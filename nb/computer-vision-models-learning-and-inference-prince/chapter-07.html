<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Modeling Complex Data Densities &#8212; All Things Phi</title>
    <link rel="stylesheet" href="../../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/my-styles.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdn.rawgit.com/mathjax/MathJax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="shortcut icon" href="../../_static/phi.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Regression Models" href="chapter-08.html" />
    <link rel="prev" title="Learning and Inference in Vision" href="chapter-06.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../../_static/js/jquery-1.11.0.min.js "></script>
<script type="text/javascript" src="../../_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="../../_static/bootstrap-3.3.7/js/bootstrap.min.js "></script>
<script type="text/javascript" src="../../_static/bootstrap-sphinx.js "></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../index.html">
          All Things Phi</a>
        <span class="navbar-text navbar-version pull-left"><b></b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../../index.html">Archive <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/12/20/mask-r-cnn.html">Mask R-CNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/12/19/rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation.html">Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/12/18/watertight-ray-triangle-intersection.html">Watertight Ray/Triangle Intersection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/12/17/understanding-deep-learning-requires-rethinking-generalization.html">Understanding Deep Learning Requires Rethinking Generalization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/12/16/accurate-large-minibatch-sgd-training-imagenet-in-1-hour.html">Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/12/15/on-large-batch-training-for-deep-learning-generalization-gap-and-sharp-minima.html">On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/12/14/layer-normalization.html">Layer Normalization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/12/13/batch-normalization-accelerating-deep-network-training-by-reducing-internal-covariate-shift.html">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/12/12/deep-residual-learning-for-image-recognition.html">Deep Residual Learning for Image Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/12/11/optimal-step-nonrigid-icp-algorithms-for-surface-registration.html">Optimal Step Nonrigid ICP Algorithms for Surface Registration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/12/10/delving-deep-into-rectifiers-surpassing-human-level-performance-on-imagenet-classification.html">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/12/09/least-squares-estimation-of-transformation-parameters-between-two-point-patterns.html">Least-Squares Estimation of Transformation Parameters Between Two Point Sets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/12/08/a-fast-learning-algorithm-for-deep-belief-nets.html">A Fast Learning Algorithm for Deep Belief Nets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/12/07/a-view-of-the-EM-algorithm-that-justifies-incremental-sparse-and-other-variants.html">A View of the EM Algorithm that Justifies Incremental, Sparse, and Other Variants</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/12/06/one-weird-trick-for-parallelizing-convolutional-neural-networks.html">One Weird Trick for Parallelizing Convolutional Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/12/05/exponential-family-harmoniums-with-an-application-to-information-retrieval.html">Exponential Family Harmoniums with an Application to Information Retrieval</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/12/04/pose-space-deformation-a-unified-approach-to-shape-interpolation-and-skeleton-driven-deformation.html">Pose Space Deformation: A Unified Approach to Shape Interpolation and Skeleton-Driven Deformation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/12/02/learning-internal-representations-by-error-propagation.html">Learning Internal Representations by Error Propagation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/12/01/structuring-a-renderer-phi-ray.html">Structuring a Renderer: <span class="math notranslate nohighlight">\(\varphi\)</span>-Ray</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/11/30/information-processing-in-dynamical-systems-foundations-of-harmony-theory.html">Information Processing in Dynamical Systems: Foundations of Harmony Theory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/11/29/an-introduction-to-the-conjugate-gradient-method-without-the-agonizing-pain.html">An Introduction to the Conjugate Gradient Method Without the Agonizing Pain</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/11/28/a-learning-algorithm-for-boltzmann-machines.html">A Learning Algorithm for Boltzmann Machines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/11/27/geometric-skinning-with-approximate-dual-quaternion-blending.html">Geometric Skinning with Approximate Dual Quaternion Blending</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/11/26/the-perceptron-a-probabilistic-model-for-information-storage-and-organization-in-the-brain.html">The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/11/25/the-sharpe-ratio.html">The Sharpe Ratio</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/11/24/neural-networks-and-physical-systems-with-emergent-collective-computational-abilities.html">Neural Networks and Physical Systems with Emergent Collective Computational Abilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/11/23/training-products-of-experts-by-minimizing-contrastive-divergence.html">Training Products of Experts by Minimizing Contrastive Divergence</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/11/22/market-timing-with-candlestick-technical-analysis.html">Market Timing with Candlestick Technical Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/11/21/all-that-glitters-is-not-gold-comparing-backtest-and-out-of-sample-performance-on-a-large-cohort-of-trading-algorithms.html">All that Glitters is Not Gold: Comparing Backtest and Out-of-Sample Performance on a Large Cohort of Trading Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/11/20/easy-volatility-investing.html">Easy Volatility Investing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/11/19/a-tutorial-on-helmholtz-machines.html">A Tutorial on Helmholtz Machines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/11/18/when-do-stop-loss-rules-stop-losses.html">When Do Stop-Loss Rules Stop Losses?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/11/17/a-simple-implicit-measure-of-the-effective-bid-ask-spread-in-an-efficient-market.html">A Simple Implicit Measure of the Effective Bid-Ask Spread in an Efficient Market</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/11/16/asset-prices-and-trading-volume-under-fixed-transactions-costs.html">Asset Prices and Trading Volume Under Fixed Transactions Costs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/11/15/maxout-networks.html">Maxout Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/11/14/dropout-a-simple-way-to-prevent-neural-networks-from-overfitting.html">Dropout: A Simple Way to Prevent Neural Networks from Overfitting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/11/13/dropout-training-as-adaptive-regularization.html">Dropout Training as Adaptive Regularization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/11/12/model-compression.html">Model Compression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/11/11/distilling-the-knowledge-in-a-neural-network.html">Distilling the Knowledge in a Neural Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/11/10/do-deep-nets-really-need-to-be-deep.html">Do Deep Nets Really Need to be Deep?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/11/09/efficient-backprop.html">Efficient Backprop</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/11/08/stochastic-gradient-descent-tricks.html">Stochastic Gradient Descent Tricks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/11/07/automatic-differentiation-in-machine-learning-a-survey.html">Automatic Differentiation in Machine Learning: A Survey</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/11/06/econometric-models-of-limit-order-executions.html">Econometric Models of Limit-Order Executions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/11/05/multilayer-feedforward-networks-are-universal-approximators.html">Multilayer Feedforward Networks are Universal Approximators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/11/04/dendritic-computation.html">Dendritic Computation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/11/03/understanding-order-flow.html">Understanding Order Flow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/11/02/optimal-control-of-execution-costs.html">Optimal Control of Execution Costs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/11/01/risks-and-portfolio-decisions-involving-hedge-funds.html">Risks and Portfolio Decisions Involving Hedge Funds</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/10/30/coordinate-systems.html">Coordinate Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/10/28/hedge-funds-the-living-and-the-dead.html">Hedge Funds: The Living and the Dead</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/10/24/do-hedge-funds-have-enough-capital-a-value-at-risk-approach.html">Do Hedge Funds Have Enough Capital?  A Value-at-Risk Approach</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/10/23/characterizing-computer-performance-with-a-single-number.html">Characterizing Computer Performance with a Single Number</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/10/22/how-to-not-lie-with-statistics-the-correct-way-to-summarize-benchmark-results.html">How Not to Lie with Statistics: The Correct Way to Summarize Benchmark Results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/10/19/an-econometric-analysis-of-serial-correlation-and-illiquidity-in-hedge-fund-returns.html">An Econometric Analysis of Serial Correlation and Illiquidity in Hedge-Fund Returns</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/10/13/empirical-characteristics-of-dynamic-trading-strategies-the-case-of-hedge-funds.html">Empirical Characteristics of Dynamic Trading Strategies: The Case of Hedge Funds</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/10/06/orange-juice-and-weath.html">Orange Juice and Weather</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/10/04/the-adaptive-markets-hypothesis-market-efficiency-from-an-evolutionary-perspective.html">The Adaptive Markets Hypothesis: Market Efficiency from an Evolutionary Perspective</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/10/02/do-asset-prices-reflect-fundamentals-freshly-squeezed-evidence-from-the-oj-market.html">Do Asset Prices Reflect Fundamentals?  Freshly Squeezed Evidence from the OJ Market</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/09/30/neuroeconomics-how-neuroscience-can-inform-economics.html">Neuroeconomics: How Neuroscience Can Inform Economics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/09/28/drawing-inferences-from-statistics-based-on-multiyear-asset-returns.html">Drawing Inferences from Statistics based on Multiyear Asset Returns</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/09/26/when-are-contrarian-profits-due-to-stock-market-overreaction.html">When are Contrarian Profits Due to Stock Market Overreaction?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/09/24/profitability-of-momentum-strategies-an-evaluation-of-alternative-explanations.html">Profitability of Momentum Strategies: An Evaluation of Alternative Explanations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/09/22/the-restrictions-on-predictability-implied-by-rational-asset-pricing.html">The Restrictions on Predictability Implied by Rational Asset Pricing Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/09/20/the-myth-of-long-horizon-predictability.html">The Myth of Long-Horizon Predictability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/09/18/the-standard-error-of-regressions.html">The Standard Error of Regressions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/09/16/lets-take-the-con-out-of-econometrics.html">Let’s Take the Con Out of Econometrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/09/14/role-of-models-in-statistical-analysis.html">Role of Models in Statistical Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/09/12/the-experimental-generation-of-interpersonal-closeness-a-procedure-and-some-preliminary-findings.html">The Experimental Generation of Interpersonal Closeness: A Procedure and Some Preliminary Findings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/08/02/notes-on-tensorflow.html">Notes on TensorFlow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/08/01/tensorflow-tensorboard-and-docker.html">TensorFlow, TensorBoard, and Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/01/13/review-and-analysis-of-solutions-of-the-three-point-perspective-pose-estimation-problem.html">Review and Analysis of Solutions of the Three Point Perspective Pose Estimation Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/01/12/variational-learning-for-switching-state-space-models.html">Variational Learning for Switching State-Space Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/01/11/bayesian-face-recognition.html">Bayesian Face Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/01/10/robust-generative-subspace-modeling-the-subspace-t-distribution.html">Robust Generative Subspace Modeling: The Subspace <span class="math notranslate nohighlight">\(t\)</span> Distribution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/01/09/robust-subspace-mixture-models-using-t-distributions.html">Robust Subspace Mixture Models using <span class="math notranslate nohighlight">\(t\)</span>-distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/01/08/robust-mixture-modelling-using-the-t-distribution.html">Robust Mixture Modelling using the <span class="math notranslate nohighlight">\(t\)</span>-distribution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/01/07/mixtures-of-probabilistic-principal-component-analyzers.html">Mixtures of Probabilistic Principal Component Analysers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/01/06/the-em-algorithm-for-mixtures-of-factor-analyzers.html">The EM Algorithm for Mixtures of Factor Analyzers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/01/05/3d-live-real-time-captured-content-for-mixed-reality.html">3D Live: Real Time Captured Content for Mixed Reality</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/01/04/high-accuracy-stereo-depth-maps-using-structured-light.html">High-Accuracy Stereo Depth Maps Using Structured Light</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/01/03/simple-accurate-and-robust-projector-camera-calibration.html">Simple, Accurate, and Robust Projector-Camera Calibration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/01/02/multiresolution-gray-scale-and-rotation-invariant-texture-classification-with-local-binary-patterns.html">Multiresolution Gray Scale and Rotation Invariant Texture Classification with Local Binary Patterns</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2016/01/01/generative-or-discriminative-getting-the-best-of-both-worlds.html">Generative or Discriminative?  Getting the Best of Both Worlds</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2014/02/01/seda-an-architecture-for-well-conditioned,-scalable-internet-services.html">SEDA: An Architecture for Well-Conditioned, Scalable Internet Services</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2014/01/26/reconciling-environment-integration-and-component-independence.html">Reconciling Environment Integration and Component Independence</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2014/01/25/design-patterns-abstraction-and-reuse-of-object-oriented-design.html">Design Patterns: Abstraction and Reuse of Object-Oriented Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2014/01/24/a-guide-to-metaphorical-design.html">A Guide to Metaphorical Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2014/01/23/a-spiral-model-of-software-development-and-enhancement.html">A Spiral Model of Software Development and Enhancement</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2014/01/22/sequential-and-concurrent-object-oriented-programming.html">Sequential and Concurrent Object-Oriented Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2014/01/21/software-aging.html">Software Aging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2014/01/20/applying-design-by-contract.html">Applying “Design by Contract”</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2014/01/19/predicate-logic-for-software-engineering.html">Predicate Logic for Software Engineering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2014/01/18/active-design-reviews-principles-and-practices.html">Active Design Reviews: Principles and Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2014/01/17/a-rational-design-process-how-and-why-to-fake-it.html">A Rational Design Process: How and Why to Fake It</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2014/01/16/the-modular-structure-of-complex-systems.html">The Modular Structure of Complex Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2014/01/15/abstract-types-defined-as-classes-of-variables.html">Abstract Types Defined as Classes of Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2014/01/14/use-of-abstract-interfaces-in-the-development-of-software-for-embedded-computer-systems.html">Use of Abstract Interfaces in the Development of Software for Embedded Computer Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2014/01/13/the-influence-of-software-structure-on-reliability.html">The Influence of Software Structure on Reliability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2014/01/12/response-to-detected-errors-in-well-structured-programs.html">Response to Detected Errors in Well-Structured Programs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2014/01/11/the-use-of-abstract-data-types-to-simplify-program-modifications.html">The Use of Abstract Data Types to Simplify Program Modifications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2014/01/10/use-of-the-concept-of-transparency-in-the-design-of-hierarchically-structured-systems.html">Use of the Concept of Transparency in the Design of Hierarchically Structured Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2014/01/09/designing-software-for-ease-of-extension-and-contraction.html">Designing Software for Ease of Extension and Contraction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2014/01/08/on-the-design-and-development-of-program-families.html">On the Design and Development of Program Families</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2014/01/07/on-the-criteria-to-be-used-in-decomposing-systems-into-modules.html">On the Criteria to be Used in Decomposing Systems into Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2014/01/06/a-technique-for-software-module-specification-with-examples.html">A Technique for Software Module Specification with Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2014/01/05/information-distribution-aspects-of-design-methodology.html">Information Distribution Aspects of Design Methodology</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2014/01/04/a-model-of-large-program-development.html">A Model of Large Program Development</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2014/01/03/architectural-styles-and-the-design-of-network-based-software-architectures.html">Architectural Styles and the Design of Network-based Software Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2014/01/02/design-of-design.html">Design of Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2014/01/01/notes-on-the-synthesis-of-form.html">Notes on the Synthesis of Form</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2013/01/26/blogging-with-docker.html">Blogging with Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2013/01/25/typical-mercurial-usage.html">Typical Mercurial Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2013/01/24/profiling-on-linux.html">Profiling on Linux</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2013/01/23/trading-cryptocurrencies.html">Trading Cryptocurrencies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2013/01/22/notes-on-software-design.html">Notes on Software Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2013/01/21/notes-on-scraping-together-a-heterogeneous-system.html">Notes on Scraping Together a Heterogeneous System</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2013/01/20/transfer-media-files-to-mobile-device-via-vlc.html">Transfer Media Files to Mobile Device via VLC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2013/01/19/style-lessons-in-clarity-and-grace.html">Style: Lessons in Clarity and Grace</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2013/01/18/the-science-of-scientific-writing.html">The Science of Scientific Writing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2013/01/17/collection-of-notes-on-research.html">Collection of Notes on Research</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2013/01/16/typical-ffmpeg-usage.html">Typical FFmpeg Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2013/01/15/generate-svg-graphics.html">Generate SVG Graphics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2013/01/14/blogging-with-restructuredtext-a-google-domain-and-sphinx.html">Blogging with RestructuredText, a Google Domain, and Sphinx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2013/01/13/set-up-android-development-environment.html">Set Up Android Development Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2013/01/12/svegan-lifestyle.html">Svegan Lifestyle</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2013/01/11/set-up-system-programming-environment.html">Set Up System Programming Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2013/01/10/the-rise-and-fall-of-react-flux-redux-and-cycle.html">The Rise and Fall of React, Flux, Redux, and Cycle</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2013/01/09/install-graphics-and-compute-linux-mint.html">Install Graphics and Compute on Linux Mint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2013/01/08/set-up-web-development-environment.html">Set Up Web Development Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2013/01/07/vfio-tips-and-tricks.html">VFIO Tips and Tricks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2013/01/06/options-trading.html">Options Trading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2013/01/05/assimp-mesh-loader.html">Assimp Mesh Loader</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2013/01/04/set-up-data-analysis-environment.html">Set Up Data Analysis Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2013/01/03/install-nvidia-drivers-on-linux-mint.html">Install Nvidia Drivers on Linux Mint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2013/01/02/blogging-with-restructuredtext-a-google-domain-and-pelican.html">Blogging with RestructuredText, a Google Domain, and Pelican</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../blog/2013/01/01/linux-mint-installation.html">Linux Mint Installation</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../an-invitation-to-3d-vision-msks/index.html">An Invitation to 3-D Vision - Ma, Soatto, Kosecka, and Sastry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../complete-musician-laitz/index.html">The Complete Musician: An Integrated Approach to Tonal Theory, Analysis, and Listening - Laitz</a></li>
<li class="toctree-l1"><a class="reference internal" href="../computer-science-theory-for-the-information-age-hk/index.html">Computer Science Theory for the Information Age - Hopcroft &amp; Kannan</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Computer Vision: Models, Learning, and Inference - Prince</a></li>
<li class="toctree-l1"><a class="reference internal" href="../creativity-nlph/index.html">Creativity - NLPH</a></li>
<li class="toctree-l1"><a class="reference internal" href="../differential-geometry-from-a-graphics-perspective-nlph/index.html">Differential Geometry from a Graphics Perspective - NLPH</a></li>
<li class="toctree-l1"><a class="reference internal" href="../fundamentals-of-electric-circuits-as/index.html">Fundamentals of Electric Circuits - Alexander &amp; Sadiku</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linear-programming-vanderbei/index.html">Linear Programming - Vanderbei</a></li>
<li class="toctree-l1"><a class="reference internal" href="../multiple-view-geometry-hz/index.html">Multiple View Geometry in Computer Vision - Hartley &amp; Zisserman</a></li>
<li class="toctree-l1"><a class="reference internal" href="../numerical-methods-for-unconstrained-optimization-and-nonlinear-equations-ds/index.html">Numerical Methods for Unconstrained Optimization and Nonlinear Equations - Dennis &amp; Schnabel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pattern-recognition-and-machine-learning-bishop/index.html">Pattern Recognition and Machine Learning - Bishop</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reinforcement-learning-sb/index.html">Reinforcement Learning: An Introduction - Sutton &amp; Barto</a></li>
<li class="toctree-l1"><a class="reference internal" href="../stat-labs-ns/index.html">Stat Labs - Nolan &amp; Speed</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Modeling Complex Data Densities</a><ul>
<li><a class="reference internal" href="#Hidden-Variables">Hidden Variables</a></li>
<li><a class="reference internal" href="#Expectation-Maximization">Expectation Maximization</a></li>
<li><a class="reference internal" href="#Factor-Analysis">Factor Analysis</a></li>
<li><a class="reference internal" href="#Exercise-7.1">Exercise 7.1</a></li>
<li><a class="reference internal" href="#Exercise-7.2">Exercise 7.2</a></li>
<li><a class="reference internal" href="#Exercise-7.3">Exercise 7.3</a><ul>
<li><a class="reference internal" href="#(a)">(a)</a></li>
<li><a class="reference internal" href="#(b)">(b)</a></li>
<li><a class="reference internal" href="#(c)">(c)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Exercise-7.4">Exercise 7.4</a></li>
<li><a class="reference internal" href="#Exercise-7.5">Exercise 7.5</a></li>
<li><a class="reference internal" href="#Exercise-7.6">Exercise 7.6</a></li>
<li><a class="reference internal" href="#Exercise-7.7">Exercise 7.7</a></li>
<li><a class="reference internal" href="#Exercise-7.8">Exercise 7.8</a><ul>
<li><a class="reference internal" href="#(1)">(1)</a></li>
<li><a class="reference internal" href="#(2)">(2)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Exercise-7.9">Exercise 7.9</a><ul>
<li><a class="reference internal" href="#(a)">(a)</a></li>
<li><a class="reference internal" href="#(b)">(b)</a></li>
<li><a class="reference internal" href="#(c)">(c)</a></li>
<li><a class="reference internal" href="#(c.1)">(c.1)</a></li>
<li><a class="reference internal" href="#(c.2)">(c.2)</a></li>
<li><a class="reference internal" href="#(d)">(d)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Exercise-7.10">Exercise 7.10</a><ul>
<li><a class="reference internal" href="#(a)">(a)</a></li>
<li><a class="reference internal" href="#(b)">(b)</a></li>
<li><a class="reference internal" href="#(c)">(c)</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
  <li>
    <a href="chapter-06.html" title="Previous Chapter: Learning and Inference in Vision"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; Learning and ...</span>
    </a>
  </li>
  <li>
    <a href="chapter-08.html" title="Next Chapter: Regression Models"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">Regression Models &raquo;</span>
    </a>
  </li>
              
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <div class="section" id="Modeling-Complex-Data-Densities">
<h1>Modeling Complex Data Densities<a class="headerlink" href="#Modeling-Complex-Data-Densities" title="Permalink to this headline">¶</a></h1>
<div class="section" id="Hidden-Variables">
<h2>Hidden Variables<a class="headerlink" href="#Hidden-Variables" title="Permalink to this headline">¶</a></h2>
<p>Hidden (latent) variables describe the target density <span class="math notranslate nohighlight">\(Pr(x)\)</span> as the
marginalization of <span class="math notranslate nohighlight">\(Pr(x, h)\)</span> such that</p>
<div class="math notranslate nohighlight">
\[Pr(x \mid \theta) = \int Pr(x, h \mid \theta) dh.\]</div>
<p>The joint density <span class="math notranslate nohighlight">\(Pr(x, h)\)</span> can be chosen to be much simpler than the
target density <span class="math notranslate nohighlight">\(Pr(x)\)</span> while producing complex marginal distributions
when integrated.</p>
<p>The left term can be formulated as a constrained nonlinear optimization
problem (7.7).  The right term can be maximized using EM, which could lead to a
closed form solution (7.8).</p>
</div>
<div class="section" id="Expectation-Maximization">
<h2>Expectation Maximization<a class="headerlink" href="#Expectation-Maximization" title="Permalink to this headline">¶</a></h2>
<p>Figure 7.5 is a beautiful illustration of EM algorithm.</p>
</div>
<div class="section" id="Factor-Analysis">
<h2>Factor Analysis<a class="headerlink" href="#Factor-Analysis" title="Permalink to this headline">¶</a></h2>
<p>The factor analyzer describes a linear subspace with a full covariance model as</p>
<div class="math notranslate nohighlight">
\[\DeclareMathOperator{\NormDist}{Norm}
Pr(\mathbf{x}) =
\NormDist_{\mathbf{x}}\left[
  \boldsymbol{\mu},
  \boldsymbol{\Phi} \boldsymbol{\Phi}^\top + \boldsymbol{\Sigma}
\right].\]</div>
<p>Probabilistic principal component analysis is an instance of the factor
analyzer where <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> models spherical covariance.  It
has slightly fewer parameters and can be fit in closed form.</p>
</div>
<div class="section" id="Exercise-7.1">
<h2>Exercise 7.1<a class="headerlink" href="#Exercise-7.1" title="Permalink to this headline">¶</a></h2>
<p>The world state <span class="math notranslate nohighlight">\(w \in \{0, 1\}\)</span> is a discrete label indicating whether
the orange is ripe or not.</p>
<p>The observed data <span class="math notranslate nohighlight">\(\mathbf{x} \in \mathbb{R}^3\)</span> describes the averaged RGB
color of a segmented orange.</p>
<p>Suppose the given labeled training data
<span class="math notranslate nohighlight">\(\left\{ \mathbf{x}_i, w_i \right\}_{i = 1}^I\)</span> describes the multimodal
colorspace of ripe and unripe oranges.  Since the pixels have been
post-processed, outliers can be ignored.  The input dimension is low, so no need
to use factor analysis.</p>
<p>One way to model this is to separately fit a mixture of Gaussians for
each discrete label as</p>
<div class="math notranslate nohighlight">
\[Pr(\mathbf{x} \mid w) =
\sum_{k = 1}^K \lambda_{wk}
  \NormDist_\mathbf{x}\left[
    \boldsymbol{\mu}_{wk}, \boldsymbol{\Sigma}_{wk}
  \right].\]</div>
<p>There are no prior knowledge about whether oranges are ripe or unripe
when the system is used, hence <span class="math notranslate nohighlight">\(Pr(w = 0) = Pr(w = 1) = 0.5\)</span>.</p>
<p>Applying Bayes’ rule to compute the posterior over <span class="math notranslate nohighlight">\(w\)</span> gives</p>
<div class="math notranslate nohighlight">
\[Pr\left( w^\ast = 1 \mid \mathbf{x}^\ast \right) =
\frac{
  Pr\left( w^\ast = 1, \mathbf{x}^\ast \right)
}{
  Pr\left( \mathbf{x}^\ast \right)
}.\]</div>
</div>
<div class="section" id="Exercise-7.2">
<h2>Exercise 7.2<a class="headerlink" href="#Exercise-7.2" title="Permalink to this headline">¶</a></h2>
<p>Erroneous training labels can be viewed as outliers so a mixture of multivariate
t-distributions can be used instead.</p>
</div>
<div class="section" id="Exercise-7.3">
<h2>Exercise 7.3<a class="headerlink" href="#Exercise-7.3" title="Permalink to this headline">¶</a></h2>
<p>Rewriting (7.18) with Lagrange multipliers gives</p>
<div class="math notranslate nohighlight">
\[\begin{split}L &amp;= \sum_{i = 1}^I \sum_{k = 1}^K r_{ik} \log\left(
       \lambda_k \NormDist_{\mathbf{x}_i}\left[
         \boldsymbol{\mu}_k, \boldsymbol{\Sigma}_k
       \right]
     \right) +
     \nu \left( \sum_{k = 1}^K \lambda_k - 1 \right)\\
 &amp;= \sum_{i = 1}^I \sum_{k = 1}^K r_{ik}
      \left(
        \log \lambda_k -
        \frac{D}{2} \log 2 \pi -
        \frac{1}{2} \log \lvert \boldsymbol{\Sigma}_k \rvert -
        \frac{1}{2}
        (\mathbf{x}_i - \boldsymbol{\mu}_k)^\top
          \boldsymbol{\Sigma}_k^{-1} (\mathbf{x}_i - \boldsymbol{\mu}_k)
      \right) +
      \nu \left( \sum_{k = 1}^K \lambda_k - 1 \right).\end{split}\]</div>
<div class="section" id="(a)">
<h3>(a)<a class="headerlink" href="#(a)" title="Permalink to this headline">¶</a></h3>
<div class="math notranslate nohighlight">
\[\begin{split}\frac{\partial L}{\partial \lambda_k}
 &amp;= \sum_{i = 1}^I
      \frac{\partial}{\partial \lambda_k} r_{ik} \log \lambda_k +
    \nu\\
0 &amp;= \sum_{i = 1}^I \frac{r_{ik}}{\lambda_k} + \nu
     &amp; \quad &amp; r_{ik} = q_i(h_i) \text{ is a constant in the M-step}\\
\lambda_k &amp;= -\frac{\sum_{i = 1}^I r_{ik}}{\nu}\\
 &amp;= \frac{\sum_{i = 1}^I r_{ik}}{\sum_{j = 1}^K \sum_{i = 1}^I r_{ij}}\end{split}\]</div>
<p>since</p>
<div class="math notranslate nohighlight">
\[\begin{split}0 &amp;= \sum_{i = 1}^I r_{ik} + \nu \lambda_k\\
-\nu \sum_{j = 1}^K \lambda_j &amp;= \sum_{j = 1}^K \sum_{i = 1}^I r_{ij}\\
\nu &amp;= -\sum_{j = 1}^K \sum_{i = 1}^I r_{ij}
       &amp; \quad &amp; \sum_k \lambda_k = 1.\end{split}\]</div>
</div>
<div class="section" id="(b)">
<h3>(b)<a class="headerlink" href="#(b)" title="Permalink to this headline">¶</a></h3>
<div class="math notranslate nohighlight">
\[\begin{split}\frac{\partial L}{\partial \boldsymbol{\mu}_k}
 &amp;= \sum_{i = 1}^I
      \frac{\partial}{\partial \boldsymbol{\mu}_k}
      \frac{-r_{ik}}{2}
      \left(
        \mathbf{x}_i^\top \boldsymbol{\Sigma}_k^{-1} \mathbf{x}_i -
        2 \mathbf{x}_i^\top \boldsymbol{\Sigma}_k^{-1} \boldsymbol{\mu}_k +
        \boldsymbol{\mu}_k^\top \boldsymbol{\Sigma}_k^{-1} \boldsymbol{\mu}_k
      \right)\\
\boldsymbol{0}
 &amp;= \sum_{i = 1}^I
      \frac{r_{ik}}{2}
      \left(
        2 \boldsymbol{\Sigma}_k^{-1} \mathbf{x}_i -
        2 \boldsymbol{\Sigma}_k^{-1} \boldsymbol{\mu}_k
      \right)
    &amp; \quad &amp; \text{(C.28) and (C.33)}\\
 \boldsymbol{\Sigma}_k^{-1} \boldsymbol{\mu}_k \sum_{i = 1}^I r_{ik}
  &amp;= \boldsymbol{\Sigma}_k^{-1} \sum_{i = 1}^I r_{ik} \mathbf{x}_i\\
\boldsymbol{\mu}_k
 &amp;= \frac{
      \sum_{i = 1}^I r_{ik} \mathbf{x}_i
    }{
      \sum_{i = 1}^I r_{ik}
    }\end{split}\]</div>
</div>
<div class="section" id="(c)">
<h3>(c)<a class="headerlink" href="#(c)" title="Permalink to this headline">¶</a></h3>
<div class="math notranslate nohighlight">
\[\begin{split}\frac{\partial L}{\partial \boldsymbol{\Sigma}_k}
 &amp;= \sum_{i = 1}^I
      \frac{\partial}{\partial \boldsymbol{\Sigma}_k} \frac{-r_{ik}}{2}
      \left(
        \log \left\vert \boldsymbol{\Sigma}_k \right\vert +
        (\mathbf{x}_i - \boldsymbol{\mu}_k)^\top
          \boldsymbol{\Sigma}_k^{-1} (\mathbf{x}_i - \boldsymbol{\mu}_k)
        \right)\\
\boldsymbol{0}
 &amp;= \sum_{i = 1}^I
      \frac{r_{ik}}{2}
      \left[
        -\boldsymbol{\Sigma}_k^{-\top} +
        \boldsymbol{\Sigma}_k^{-\top}
          (\mathbf{x}_i - \boldsymbol{\mu}_k)
          (\mathbf{x}_i - \boldsymbol{\mu}_k)^\top
          \boldsymbol{\Sigma}_k^{-\top}
      \right]
    &amp; \quad &amp; \text{(C.38) and Matrix Cookbook Section 2.2}\\
\boldsymbol{\Sigma}_k^{-1} \sum_{i = 1}^I r_{ik}
 &amp;= \boldsymbol{\Sigma}_k^{-1}
    \left(
      \sum_{i = 1}^I r_{ik}
        (\mathbf{x}_i - \boldsymbol{\mu}_k)
        (\mathbf{x}_i - \boldsymbol{\mu}_k)^\top
    \right)
    \boldsymbol{\Sigma}_k^{-1}\\
\boldsymbol{\Sigma}_k
 &amp;= \frac{
      \sum_{i = 1}^I r_{ik}
        (\mathbf{x}_i - \boldsymbol{\mu}_k)
        (\mathbf{x}_i - \boldsymbol{\mu}_k)^\top
    }{
      \sum_{i = 1}^I r_{ik}
    }\end{split}\]</div>
</div>
</div>
<div class="section" id="Exercise-7.4">
<h2>Exercise 7.4<a class="headerlink" href="#Exercise-7.4" title="Permalink to this headline">¶</a></h2>
<div class="math notranslate nohighlight">
\[\DeclareMathOperator{\BetaDist}{Beta}
Pr(x \mid \boldsymbol{\theta}) =
\sum_{k = 1}^K \lambda_k \BetaDist_x[\alpha_k, \beta_k]\]</div>
<p>is a mixture of beta distributions where <span class="math notranslate nohighlight">\(x \in [0, 1]\)</span> is univariate and
<span class="math notranslate nohighlight">\(\boldsymbol{\theta} = \{ \alpha_k, \beta_k, \lambda_k \}_{k = 1}^K\)</span>.</p>
<p>Define a discrete hidden variable <span class="math notranslate nohighlight">\(h \in \{1 \ldots K\}\)</span> such that</p>
<div class="math notranslate nohighlight">
\[\begin{split}\DeclareMathOperator{\CatDist}{Cat}
Pr(x \mid h, \boldsymbol{\theta})
 &amp;= \BetaDist_x[\alpha_h, \beta_h]\\
Pr(h \mid \boldsymbol{\theta}) &amp;= \CatDist_h[\boldsymbol{\lambda}]\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\boldsymbol{\lambda} = \{ \lambda_1, \ldots, \lambda_K\}\)</span> are the
parameters of the categorical distribution.</p>
<p>The original density can be expressed as the marginalization of the previous
terms:</p>
<div class="math notranslate nohighlight">
\[\begin{split}Pr(x \mid \boldsymbol{\theta})
 &amp;= \sum_{h} Pr(x, h \mid \boldsymbol{\theta})\\
 &amp;= \sum_{h}
      Pr(x \mid h, \boldsymbol{\theta})
      Pr(h \mid \boldsymbol{\theta})\\
 &amp;= \sum_{k = 1}^K \lambda_k \BetaDist_x[\alpha_k, \beta_k].\end{split}\]</div>
<p>In the E-step, the goal is to compute the probability that the
<span class="math notranslate nohighlight">\(k\text{th}\)</span> beta distribution was responsible for the
<span class="math notranslate nohighlight">\(i\text{th}\)</span> data point:</p>
<div class="math notranslate nohighlight">
\[\begin{split}q_i(h_i = k)
 &amp;= Pr(h_i \mid x_i, \boldsymbol{\theta})
    &amp; \quad &amp; \text{(7.11)}\\
 &amp;= \frac{
      Pr(h_i, x_i, \boldsymbol{\theta})
    }{
      Pr(x_i, \boldsymbol{\theta})
    }\\
 &amp;= \frac{
      Pr(x_i \mid h_i, \boldsymbol{\theta}) Pr(h_i \mid \boldsymbol{\theta})
    }{
      Pr(x_i \mid \boldsymbol{\theta})
    }\\
 &amp;= \frac{
      \lambda_k \BetaDist_{x_i}[\alpha_k, \beta_k]
    }{
      \sum_{j = 1}^K \lambda_j \BetaDist_{x_i}[\alpha_j, \beta_j]
    }\\
 &amp;= r_{ik}.\end{split}\]</div>
<p>In the M-step, the goal is to maximize the lower bound approximation with
respect to <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> such that</p>
<div class="math notranslate nohighlight">
\[\begin{split}\DeclareMathOperator*{\argmax}{arg\,max}
\hat{\boldsymbol{\theta}}
 &amp;= \argmax_{\boldsymbol{\theta}}
      \sum_{i = 1}^I \sum_{k = 1}^k
        q_i(h_i = k)
        \log Pr(x_i, h_i = k \mid \boldsymbol{\theta})
    &amp; \quad &amp; \text{(7.12)}\\
 &amp;= \argmax_{\boldsymbol{\theta}}
      \sum_{i = 1}^I \sum_{k = 1}^k
        r_{ik} \log \lambda_k \BetaDist_{x_i}[\alpha_k, \beta_k].\end{split}\]</div>
</div>
<div class="section" id="Exercise-7.5">
<h2>Exercise 7.5<a class="headerlink" href="#Exercise-7.5" title="Permalink to this headline">¶</a></h2>
<div class="math notranslate nohighlight">
\[\begin{split}\DeclareMathOperator{\GamDist}{Gam}
\DeclareMathOperator{\StudDist}{Stud}
Pr(x) &amp;= \int Pr(x, h) dh\\
 &amp;= \int Pr(x \mid h) Pr(h) dh\\
 &amp;= \int_0^\infty
      \NormDist_x\left[ \mu, \sigma^2 / h \right]
      \GamDist_h[\nu / 2, \nu / 2] dh
    &amp; \quad &amp; \text{Gamma distribution is defined on } (0, \infty)\\
 &amp;= \int_0^\infty
      \frac{
        h^{1/2}
      }{
        \sqrt{2 \pi \sigma^2}
      }
      \exp\left[
        -\frac{(x - \mu)^2}{2 \sigma^2} h
      \right]
      \frac{
        \left( \frac{\nu}{2} \right)^{\nu / 2}
      }{
        \Gamma\left[ \frac{\nu}{2} \right]
      }
      \exp\left[ -\frac{\nu}{2} h \right] h^{\nu / 2 - 1} dh\\
 &amp;= \frac{
      \nu^{\nu / 2}
    }{
      2^{\nu / 2} \sqrt{2 \pi \sigma^2} \Gamma\left[ \frac{\nu}{2} \right]
    }
    \int_0^\infty \exp\left[
      -\left(
        \frac{\nu}{2} + \frac{(x - \mu)^2}{2 \sigma^2}
      \right) h
    \right] h^{(\nu - 1) / 2} dh\\
 &amp;= \frac{
      \nu^{\nu / 2}
    }{
      2^{\nu / 2} \sqrt{2 \pi \sigma^2} \Gamma[\frac{\nu}{2}]
    }
    \left(
      \frac{\nu}{2} + \frac{(x - \mu)^2}{2 \sigma^2}
    \right)^{-(v + 1) / 2}
    \Gamma\left[ \frac{\nu + 1}{2} \right]
    &amp; \quad &amp; \int_0^\infty x^n \exp\left[ -a x^b \right] dx =
              b^{-1} a^{-(n + 1) / b} \Gamma\left[ \frac{n + 1}{b} \right]\\
 &amp;= \frac{
      \nu^{\nu / 2}
    }{
      \sqrt{\pi \sigma^2} \Gamma\left[ \frac{\nu}{2} \right]
    }
    \left(
      \nu + \frac{(x - \mu)^2}{\sigma^2}
    \right)^{-(v + 1) / 2}
    \Gamma\left[ \frac{\nu + 1}{2} \right]\\
 &amp;= \frac{1}{
      \sqrt{\nu \pi \sigma^2} \Gamma\left[ \frac{\nu}{2} \right]
    }
    \left(
      1 + \frac{(x - \mu)^2}{\nu \sigma^2}
    \right)^{-(v + 1) / 2}
    \Gamma\left[ \frac{\nu + 1}{2} \right]\\
 &amp;= \frac{
      \Gamma\left[ \frac{\nu + 1}{2} \right]
    }{
      \sqrt{\nu \pi \sigma^2}
      \Gamma\left[ \frac{\nu}{2} \right]
    }
    \left(
      1 + \frac{(x - \mu)^2}{\nu \sigma^2}
    \right)^{-\frac{\nu + 1}{2}}\\
 &amp;= \StudDist_x\left[ \mu, \sigma^2, \nu \right].\end{split}\]</div>
</div>
<div class="section" id="Exercise-7.6">
<h2>Exercise 7.6<a class="headerlink" href="#Exercise-7.6" title="Permalink to this headline">¶</a></h2>
<div class="math notranslate nohighlight">
\[\begin{split}\frac{\partial}{\partial z} \GamDist_z[\alpha, \beta]
 &amp;= \frac{\partial}{\partial z}
    \frac{\beta^\alpha}{\Gamma[\alpha]}
    \exp[-\beta z] z^{\alpha - 1}\\
0 &amp;= \frac{\beta^\alpha}{\Gamma[\alpha]}
     \left(
       -\beta \exp[-\beta z] z^{\alpha - 1} +
       (\alpha - 1) \exp[-\beta z] z^{\alpha - 2}
     \right)\\
\beta z^{\alpha - 1} &amp;= (\alpha - 1) z^{\alpha - 2}\\
z &amp;= \frac{\alpha - 1}{\beta}\end{split}\]</div>
</div>
<div class="section" id="Exercise-7.7">
<h2>Exercise 7.7<a class="headerlink" href="#Exercise-7.7" title="Permalink to this headline">¶</a></h2>
<div class="math notranslate nohighlight">
\[\begin{split}&amp; \NormDist_{\mathbf{x}}[\boldsymbol{\mu}, \boldsymbol{\Sigma} / h]
  \GamDist_{h}[\nu / 2, \nu / 2]\\
 &amp;= \frac{
      h^{D / 2}
    }{
      (2 \pi)^{D / 2} \lvert \boldsymbol{\Sigma} \rvert^{1 / 2}
    }
    \exp\left[
      -\frac{
        (\mathbf{x} - \boldsymbol{\mu})^\top
        \boldsymbol{\Sigma}^{-1}
        (\mathbf{x} - \boldsymbol{\mu})
      }{2} h
    \right]
    \frac{\nu^{\nu / 2}}{2^{\nu / 2} \Gamma[\nu / 2]}
    \exp\left[ -\frac{\nu}{2} h \right] h^{\nu / 2 - 1}\\
 &amp;= \frac{
      \nu^{\nu / 2}
    }{
      (2 \pi)^{D / 2}
      \lvert \boldsymbol{\Sigma} \rvert^{1 / 2}
      \Gamma[\nu / 2]
      2^{\nu / 2}
    }
    \exp\left[
      -\frac{
        (\mathbf{x} - \boldsymbol{\mu})^\top
          \boldsymbol{\Sigma}^{-1} (\mathbf{x} - \boldsymbol{\mu}) +
        \nu
      }{2} h
    \right]
    h^{(\nu + D) / 2 - 1}\\
 &amp;= \frac{
      \nu^{\nu / 2}
    }{
      (2 \pi)^{D / 2}
      \lvert \boldsymbol{\Sigma} \rvert^{1 / 2}
      \Gamma[\nu / 2]
      2^{\nu / 2}
    }
    \exp[-\beta h] h^{\alpha - 1}\\
 &amp;= \kappa \GamDist_h[\alpha, \beta]\end{split}\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\begin{split}\alpha &amp;= \frac{\nu + D}{2}\\\\
\beta &amp;= \frac{
           (\mathbf{x} - \boldsymbol{\mu})^\top
             \boldsymbol{\Sigma}^{-1} (\mathbf{x} - \boldsymbol{\mu}) +
           \nu
         }{2}\\\\
\kappa
 &amp;= \frac{
      \nu^{\nu / 2} \Gamma[\alpha]
    }{
      (2 \pi)^{D / 2} \lvert \boldsymbol{\Sigma} \rvert^{1 / 2}
      \Gamma[\nu / 2] 2^{\nu / 2} \beta^\alpha
    }\\
 &amp;= \frac{
      \nu^{\nu / 2} \Gamma[\alpha]
    }{
      (2 \pi)^{D / 2} \lvert \boldsymbol{\Sigma} \rvert^{1 / 2}
      \Gamma[\nu / 2] 2^{\nu / 2}
    }
    \left( \frac{\nu}{2} \right)^{-\alpha}
    \left(
      \frac{
        (\mathbf{x} - \boldsymbol{\mu})^\top
        \boldsymbol{\Sigma}^{-1}
        (\mathbf{x} - \boldsymbol{\mu})
      }{\nu} + 1
    \right)^{-\alpha}\\
 &amp;= \StudDist_{\mathbf{x}}[\boldsymbol{\mu}, \boldsymbol{\Sigma}, \nu].\end{split}\]</div>
</div>
<div class="section" id="Exercise-7.8">
<span id="prince2012computer-ex-7-8"></span><h2>Exercise 7.8<a class="headerlink" href="#Exercise-7.8" title="Permalink to this headline">¶</a></h2>
<p>Let <span class="math notranslate nohighlight">\(\mathbf{x}_i =
\boldsymbol{\mu} + \boldsymbol{\Phi} \mathbf{h}_i + \boldsymbol{\epsilon}_i\)</span>
where</p>
<div class="math notranslate nohighlight">
\[\begin{split}\DeclareMathOperator{\E}{\mathrm{E}}
\DeclareMathOperator{\Cov}{\mathrm{Cov}}
\begin{gather*}
  \E[\mathbf{h}_i] = \E[\boldsymbol{\epsilon}_i] = \boldsymbol{0}\\
  \Cov(\mathbf{h}_i, \mathbf{h}_i) =
    \E\left[
      (\mathbf{h}_i - \E[\mathbf{h}_i])
      (\mathbf{h}_i - \E[\mathbf{h}_i])^\top
    \right] =
    \E\left[ \mathbf{h}_i \mathbf{h}_i^\top \right] = I\\
  \Cov(\boldsymbol{\epsilon}_i, \boldsymbol{\epsilon}_i) =
    \E\left[
      (\boldsymbol{\epsilon}_i - \E[\boldsymbol{\epsilon}_i])
      (\boldsymbol{\epsilon}_i - \E[\boldsymbol{\epsilon}_i])^\top
    \right] =
    \E\left[ \boldsymbol{\epsilon}_i \boldsymbol{\epsilon}_i^\top \right] =
    \boldsymbol{\Sigma}\\
\Cov(\mathbf{h}_i, \boldsymbol{\epsilon}_i) =
  \E\left[
    (\mathbf{h}_i - \E[\mathbf{h}_i])
    (\boldsymbol{\epsilon}_i - \E[\boldsymbol{\epsilon}_i])^\top
  \right] =
  \E\left[ \mathbf{h}_i \boldsymbol{\epsilon}_i^\top \right] =
  \boldsymbol{0}\\
\Cov(\boldsymbol{\epsilon}_i, \mathbf{h}_i) =
  \Cov(\mathbf{h}_i, \boldsymbol{\epsilon}_i)^\top = \boldsymbol{0}
\end{gather*}\end{split}\]</div>
<div class="section" id="(1)">
<h3>(1)<a class="headerlink" href="#(1)" title="Permalink to this headline">¶</a></h3>
<div class="math notranslate nohighlight">
\[\begin{split}\E[\mathbf{x}_i]
 &amp;= \E[\boldsymbol{\mu}] +
    \E[\boldsymbol{\Phi} \mathbf{h}_i] +
    \E[\boldsymbol{\epsilon}_i]
    &amp; \quad &amp; \text{(2.16)}\\
 &amp;= \boldsymbol{\mu} +
    \boldsymbol{\Phi} \E[\mathbf{h}_i] +
    \boldsymbol{0}
    &amp; \quad &amp; \text{(2.14), (2.15), (2.16)}\\
 &amp;= \boldsymbol{\mu} + \boldsymbol{\Phi} \boldsymbol{0}\\
 &amp;= \boldsymbol{\mu}\end{split}\]</div>
</div>
<div class="section" id="(2)">
<h3>(2)<a class="headerlink" href="#(2)" title="Permalink to this headline">¶</a></h3>
<div class="math notranslate nohighlight">
\[\begin{split}\E\left[
  (\mathbf{x}_i - \E[\mathbf{x}_i])
  (\mathbf{x}_i - \E[\mathbf{x}_i])^\top
\right]
 &amp;= \E\left[
      (\mathbf{x}_i - \boldsymbol{\mu})
      (\mathbf{x}_i - \boldsymbol{\mu})^\top
    \right]\\
 &amp;= \E\left[
      (\boldsymbol{\Phi} \mathbf{h}_i + \boldsymbol{\epsilon}_i)
      (\boldsymbol{\Phi} \mathbf{h}_i + \boldsymbol{\epsilon}_i)^\top
    \right]\\
 &amp;= \E\left[
      \boldsymbol{\Phi} \mathbf{h}_i \mathbf{h}_i^\top \boldsymbol{\Phi}^\top
    \right] +
    \E\left[
      \boldsymbol{\Phi} \mathbf{h}_i \boldsymbol{\epsilon}_i^\top
    \right] +
    \E\left[
      \boldsymbol{\epsilon}_i \mathbf{h}_i^\top \boldsymbol{\Phi}^\top
    \right] +
    \E\left[ \boldsymbol{\epsilon}_i \boldsymbol{\epsilon}_i^\top \right]
    &amp; \quad &amp; \text{(2.16)}\\
 &amp;= \boldsymbol{\Phi} \boldsymbol{\Phi}^\top +
    \boldsymbol{\Phi} \E\left[
      \mathbf{h}_i \boldsymbol{\epsilon}_i^\top
    \right] +
    \E\left[ \boldsymbol{\epsilon}_i \mathbf{h}_i^\top \right]
      \boldsymbol{\Phi}^\top +
    \boldsymbol{\Sigma}
    &amp; \quad &amp; \text{(2.15), (2.16)}\\
 &amp;= \boldsymbol{\Phi} \boldsymbol{\Phi}^\top + \boldsymbol{\Sigma}\end{split}\]</div>
</div>
</div>
<div class="section" id="Exercise-7.9">
<span id="prince2012computer-ex-7-9"></span><h2>Exercise 7.9<a class="headerlink" href="#Exercise-7.9" title="Permalink to this headline">¶</a></h2>
<div class="math notranslate nohighlight">
\[\begin{split}q_i(\mathbf{h}_i)
 &amp;= Pr(\mathbf{h}_i \mid \mathbf{x}_i, \boldsymbol{\theta})
    &amp; \quad &amp; \text{(7.11)}\\
 &amp;= \frac{
      Pr(\mathbf{x}_i \mid \mathbf{h}_i, \boldsymbol{\theta})
      Pr(\mathbf{h}_i \mid \boldsymbol{\theta})
    }{
      Pr(\mathbf{x}_i \mid \boldsymbol{\theta})
    }\\
 &amp;= \frac{
      \NormDist_{\mathbf{x}_i}\left[
        \boldsymbol{\mu} + \boldsymbol{\Phi} \mathbf{h}_i,
        \boldsymbol{\Sigma}
      \right]
      \NormDist_{\mathbf{h}_i}\left[ \boldsymbol{0}, \mathbf{I} \right]
    }{
      \NormDist_{\mathbf{x}_i}\left[
        \boldsymbol{\mu},
        \boldsymbol{\Phi} \boldsymbol{\Phi}^\top + \boldsymbol{\Sigma}
      \right]
    }\\
 &amp;= \frac{
      \kappa_1 \NormDist_{\mathbf{h}_i}\left[
        \boldsymbol{\Phi}' \mathbf{x}_i + \boldsymbol{\mu}',
        \boldsymbol{\Sigma}'
      \right]
      \NormDist_{\mathbf{h}_i}\left[ \boldsymbol{0}, \mathbf{I} \right]
    }{
      \NormDist_{\mathbf{x}_i}\left[
        \boldsymbol{\mu},
        \boldsymbol{\Phi} \boldsymbol{\Phi}^\top + \boldsymbol{\Sigma}
      \right]
    }
    &amp; \quad &amp; \text{(a), (5.17), and Exercise 5.10}\\
 &amp;= \frac{
      \kappa_1 \kappa_2 \NormDist_{\mathbf{h}_i}\left[
        \hat{\boldsymbol{\mu}}, \hat{\boldsymbol{\Sigma}}
      \right]
    }{
      \NormDist_{\mathbf{x}_i}\left[
        \boldsymbol{\mu},
        \boldsymbol{\Phi} \boldsymbol{\Phi}^\top + \boldsymbol{\Sigma}
      \right]
    }
    &amp; \quad &amp; \text{(b), (5.14), (5.15), and Exercise 5.7 &amp; 5.9}\\
 &amp;= \NormDist_{\mathbf{h}_i}\left[
      \hat{\boldsymbol{\mu}}, \hat{\boldsymbol{\Sigma}}
    \right]
    &amp; \quad &amp; \text{(c)}\end{split}\]</div>
<p>See <a class="reference internal" href="chapter-05.html#prince2012computer-ex-5-7"><span class="std std-ref">Exercise 5.7</span></a>,
<a class="reference internal" href="chapter-05.html#prince2012computer-ex-5-9"><span class="std std-ref">Exercise 5.9</span></a>, and
<a class="reference internal" href="chapter-05.html#prince2012computer-ex-5-10"><span class="std std-ref">Exercise 5.10</span></a> for details.</p>
<div class="section" id="(a)">
<h3>(a)<a class="headerlink" href="#(a)" title="Permalink to this headline">¶</a></h3>
<div class="math notranslate nohighlight">
\[\begin{split}\boldsymbol{\Sigma}' &amp;=
  \left(
    \boldsymbol{\Phi}^\top \boldsymbol{\Sigma}^{-1} \boldsymbol{\Phi}
  \right)^{-1}\\\\
\boldsymbol{\Phi}' &amp;=
  \boldsymbol{\Sigma}' \boldsymbol{\Phi}^\top \boldsymbol{\Sigma}^{-1}\\\\
\boldsymbol{\mu}' &amp;=
  -\boldsymbol{\Sigma}'
  \boldsymbol{\Phi}^\top \boldsymbol{\Sigma}^{-1} \boldsymbol{\mu}\\\\
\kappa_1 &amp;=
  \frac{
    \left\vert \boldsymbol{\Sigma}' \right\vert^{1 / 2}
  }{
    \left\vert \boldsymbol{\Sigma} \right\vert^{1 / 2}
  }
  \exp\left[
    (\mathbf{x}_i - \boldsymbol{\mu})^\top
    \left(
      \boldsymbol{\Sigma}^{-1} -
      \boldsymbol{\Sigma}^{-1} \boldsymbol{\Phi}
        \boldsymbol{\Sigma}' \boldsymbol{\Phi}^\top \boldsymbol{\Sigma}^{-1}
    \right)
    (\mathbf{x}_i - \boldsymbol{\mu})
  \right]^{-0.5}\end{split}\]</div>
</div>
<div class="section" id="(b)">
<h3>(b)<a class="headerlink" href="#(b)" title="Permalink to this headline">¶</a></h3>
<div class="math notranslate nohighlight">
\[\begin{split}\hat{\boldsymbol{\Sigma}}
 &amp;= \left( \boldsymbol{\Sigma}'^{-1} + \mathbf{I}^{-1} \right)^{-1}\\
 &amp;= \left(
      \boldsymbol{\Phi}^\top \boldsymbol{\Sigma}^{-1} \boldsymbol{\Phi} +
      \mathbf{I}
    \right)^{-1}\\\\
\hat{\boldsymbol{\mu}}
 &amp;= \hat{\boldsymbol{\Sigma}}
    \left(
      \boldsymbol{\Sigma}'^{-1} \left(
        \boldsymbol{\Phi}' \mathbf{x}_i + \boldsymbol{\mu}'
      \right) +
      \mathbf{I}^{-1} \boldsymbol{0}
    \right)\\
 &amp;= \hat{\boldsymbol{\Sigma}}
    \boldsymbol{\Phi}^\top \boldsymbol{\Sigma}^{-1}
    (\mathbf{x}_i - \boldsymbol{\mu})\\\\
\kappa_2
 &amp;= \NormDist_{\boldsymbol{\Phi}' \mathbf{x}_i + \boldsymbol{\mu}'}\left[
      \boldsymbol{0}, \boldsymbol{\Sigma}' + \mathbf{I}
    \right]\\
 &amp;= \NormDist_{\boldsymbol{0}}\left[
      \boldsymbol{\Phi}' \mathbf{x}_i + \boldsymbol{\mu}',
      \boldsymbol{\Sigma}' + \mathbf{I}
    \right]\\
 &amp;= \frac{1}{
      (2 \pi)^{D / 2} \lvert \boldsymbol{\Sigma}' + \mathbf{I} \rvert^{1 / 2}
    }
    \exp\left[
      \left( \boldsymbol{\Phi}' \mathbf{x}_i + \boldsymbol{\mu}' \right)^\top
      \left( \boldsymbol{\Sigma}' + \mathbf{I} \right)^{-1}
      \left( \boldsymbol{\Phi}' \mathbf{x}_i + \boldsymbol{\mu}' \right)
    \right]^{-0.5}\\
 &amp;= \frac{1}{
      (2 \pi)^{D / 2} \lvert \boldsymbol{\Sigma}' + \mathbf{I} \rvert^{1 / 2}
    }
    \exp\left[
      (\mathbf{x}_i - \boldsymbol{\mu})^\top
      \boldsymbol{\Sigma}^{-1} \boldsymbol{\Phi} \boldsymbol{\Sigma}'
      \left( \boldsymbol{\Sigma}' + \mathbf{I} \right)^{-1}
      \boldsymbol{\Sigma}' \boldsymbol{\Phi}^\top \boldsymbol{\Sigma}^{-1}
      (\mathbf{x}_i - \boldsymbol{\mu})
    \right]^{-0.5}\end{split}\]</div>
</div>
<div class="section" id="(c)">
<h3>(c)<a class="headerlink" href="#(c)" title="Permalink to this headline">¶</a></h3>
<div class="math notranslate nohighlight">
\[\begin{split}\kappa_1 \kappa_2
 &amp;= \frac{
      \left\vert \boldsymbol{\Sigma}' \right\vert^{1 / 2}
    }{
      \left\vert \boldsymbol{\Sigma} \right\vert^{1 / 2}
    }
    \exp\left[
      (\mathbf{x}_i - \boldsymbol{\mu})^\top
      \left(
        \boldsymbol{\Sigma}^{-1} -
        \boldsymbol{\Sigma}^{-1} \boldsymbol{\Phi} \boldsymbol{\Sigma}'
          \boldsymbol{\Phi}^\top \boldsymbol{\Sigma}^{-1}
      \right)
      (\mathbf{x}_i - \boldsymbol{\mu})
    \right]^{-0.5}
    \NormDist_{\boldsymbol{0}}\left[
      \boldsymbol{\Phi}' \mathbf{x}_i + \boldsymbol{\mu}',
      \boldsymbol{\Sigma}' + \mathbf{I}
    \right]\\
 &amp;= \frac{
      \left\vert \boldsymbol{\Sigma}' \right\vert^{1 / 2}
    }{
      (2 \pi)^{D / 2} \left\vert \boldsymbol{\Sigma} \right\vert^{1 / 2}
      \left\vert \boldsymbol{\Sigma}' + \mathbf{I} \right\vert^{1 / 2}
    }
    \exp\left[
      (\mathbf{x}_i - \boldsymbol{\mu})^\top
      \left(
        \boldsymbol{\Sigma}^{-1} -
        \boldsymbol{\Sigma}^{-1} \boldsymbol{\Phi} \boldsymbol{\Sigma}'
          \boldsymbol{\Phi}^\top \boldsymbol{\Sigma}^{-1} +
        \boldsymbol{\Sigma}^{-1} \boldsymbol{\Phi} \boldsymbol{\Sigma}'
          \left( \boldsymbol{\Sigma}' + \mathbf{I} \right)^{-1}
          \boldsymbol{\Sigma}' \boldsymbol{\Phi}^\top
          \boldsymbol{\Sigma}^{-1}
      \right)
      (\mathbf{x}_i - \boldsymbol{\mu})
    \right]^{-0.5}\\
 &amp;= \frac{1}{
      (2 \pi)^{D / 2} \left\vert \boldsymbol{\Sigma} \right\vert^{1 / 2}
      \left\vert \boldsymbol{\Sigma}'^{-1} + \mathbf{I} \right\vert^{1 / 2}
    }
    \exp\left[
      (\mathbf{x} - \boldsymbol{\mu})^\top
      \left(
        \boldsymbol{\Sigma}^{-1} -
        \boldsymbol{\Sigma}^{-1} \boldsymbol{\Phi}
        \left(
          \boldsymbol{\Sigma}' -
          \boldsymbol{\Sigma}'
            \left( \boldsymbol{\Sigma}' + \mathbf{I} \right)^{-1}
            \boldsymbol{\Sigma}'
        \right)
        \boldsymbol{\Phi}^\top \boldsymbol{\Sigma}^{-1}
      \right)
      (\mathbf{x} - \boldsymbol{\mu})
    \right]^{-0.5}\\
 &amp;= \frac{1}{
      (2 \pi)^{D / 2}
      \left\vert
        \boldsymbol{\Sigma} + \boldsymbol{\Phi} \boldsymbol{\Phi}^\top
      \right\vert^{1 / 2}
    }
    \exp\left[
      (\mathbf{x} - \boldsymbol{\mu})^\top
      \left(
        \boldsymbol{\Sigma}^{-1} -
        \boldsymbol{\Sigma}^{-1} \boldsymbol{\Phi}
          \left( \mathbf{I} + \boldsymbol{\Sigma}'^{-1} \right)^{-1}
          \boldsymbol{\Phi}^\top \boldsymbol{\Sigma}^{-1}
      \right)
      (\mathbf{x} - \boldsymbol{\mu})
    \right]^{-0.5}
    &amp; \quad &amp; \text{(c.1) and (d)}\\
 &amp;= \frac{1}{
      (2 \pi)^{D / 2}
      \left\vert
        \boldsymbol{\Sigma} + \boldsymbol{\Phi} \boldsymbol{\Phi}^\top
      \right\vert^{1 / 2}
    }
    \exp\left[
      (\mathbf{x} - \boldsymbol{\mu})^\top
      \left(
        \boldsymbol{\Sigma} + \boldsymbol{\Phi} \boldsymbol{\Phi}^\top
      \right)^{-1}
      (\mathbf{x} - \boldsymbol{\mu})
    \right]^{-0.5}
    &amp; \quad &amp; \text{Sherman–Morrison–Woodbury formula}\\
 &amp;= \NormDist_{\mathbf{x}_i}\left[
      \boldsymbol{\mu},
      \boldsymbol{\Phi} \boldsymbol{\Phi}^\top + \boldsymbol{\Sigma}
    \right]\end{split}\]</div>
</div>
<div class="section" id="(c.1)">
<h3>(c.1)<a class="headerlink" href="#(c.1)" title="Permalink to this headline">¶</a></h3>
<div class="math notranslate nohighlight">
\[\begin{split}\left(
  \boldsymbol{\Sigma}' -
  \boldsymbol{\Sigma}'
    \left( \mathbf{I} + \boldsymbol{\Sigma}'\right)^{-1} \boldsymbol{\Sigma}'
\right)
\left( \mathbf{I} + \boldsymbol{\Sigma}'^{-1} \right)
 &amp;= \boldsymbol{\Sigma}' + \mathbf{I} -
    \boldsymbol{\Sigma}'
      \left( \mathbf{I} + \boldsymbol{\Sigma}' \right)^{-1}
      \boldsymbol{\Sigma}' -
    \boldsymbol{\Sigma}'
      \left( \mathbf{I} + \boldsymbol{\Sigma}' \right)^{-1}\\
 &amp;= \mathbf{I} +
    \boldsymbol{\Sigma}' \left[
      \mathbf{I} - \left( \mathbf{I} + \boldsymbol{\Sigma}' \right)^{-1}
    \right] -
    \boldsymbol{\Sigma}'
      \left( \mathbf{I} + \boldsymbol{\Sigma}' \right)^{-1}
      \boldsymbol{\Sigma}'\\
 &amp;= \mathbf{I}
    &amp; \quad &amp; \text{(c.2)}\\
\left(
  \boldsymbol{\Sigma}' -
  \boldsymbol{\Sigma}'
    \left( \mathbf{I} + \boldsymbol{\Sigma}' \right)^{-1}
    \boldsymbol{\Sigma}'
\right)
 &amp;= \left( \mathbf{I} + \boldsymbol{\Sigma}'^{-1} \right)^{-1}\end{split}\]</div>
</div>
<div class="section" id="(c.2)">
<h3>(c.2)<a class="headerlink" href="#(c.2)" title="Permalink to this headline">¶</a></h3>
<div class="math notranslate nohighlight">
\[\begin{split}\left( \mathbf{I} + \boldsymbol{\Sigma}' \right) \boldsymbol{\Sigma}'^{-1}
 &amp;= \boldsymbol{\Sigma}'^{-1} + \mathbf{I}
    &amp; \quad &amp; \text{Exercise 5.9}\\
\boldsymbol{\Sigma}'^{-1}
 &amp;= \left( \mathbf{I} + \boldsymbol{\Sigma}' \right)^{-1}
    \left( \boldsymbol{\Sigma}'^{-1} + \mathbf{I} \right)\\
\boldsymbol{\Sigma}'^{-1} -
  \left( \mathbf{I} + \boldsymbol{\Sigma}' \right)^{-1}
  \boldsymbol{\Sigma}'^{-1}
 &amp;= \left( \mathbf{I} + \boldsymbol{\Sigma}' \right)^{-1}\\
\mathbf{I} - \left( \mathbf{I} + \boldsymbol{\Sigma}' \right)^{-1}
 &amp;= \left( \mathbf{I} + \boldsymbol{\Sigma}' \right)^{-1}
    \boldsymbol{\Sigma}'\\
\boldsymbol{\Sigma}' \left[
  \mathbf{I} - \left( \mathbf{I} + \boldsymbol{\Sigma}' \right)^{-1}
\right]
 &amp;= \boldsymbol{\Sigma}'
    \left( \mathbf{I} + \boldsymbol{\Sigma}' \right)^{-1}
    \boldsymbol{\Sigma}'\end{split}\]</div>
</div>
<div class="section" id="(d)">
<h3>(d)<a class="headerlink" href="#(d)" title="Permalink to this headline">¶</a></h3>
<div class="math notranslate nohighlight">
\[\begin{split}\left(
  \left\vert \boldsymbol{\Sigma} \right\vert
  \left\vert \boldsymbol{\Sigma}'^{-1} + \mathbf{I} \right\vert
\right)^{-1 / 2}
 &amp;= \left(
      \left\vert \boldsymbol{\Sigma} \right\vert
      \left\vert
        \mathbf{I} +
        \boldsymbol{\Phi}^\top \boldsymbol{\Sigma}^{-1} \boldsymbol{\Phi}
      \right\vert
    \right)^{-1 / 2}\\
 &amp;= \left\vert
      \boldsymbol{\Sigma} + \boldsymbol{\Phi} \boldsymbol{\Phi}^\top
    \right\vert^{-1 / 2}
    &amp; \quad &amp; \text{Sylvester's determinant theorem}\end{split}\]</div>
</div>
</div>
<div class="section" id="Exercise-7.10">
<h2>Exercise 7.10<a class="headerlink" href="#Exercise-7.10" title="Permalink to this headline">¶</a></h2>
<div class="math notranslate nohighlight">
\[\begin{split}\hat{\boldsymbol{\theta}}
 &amp;= \argmax_\boldsymbol{\theta}
      \sum_{i = 1}^I \sum_{k = 1}^k q_i(\mathbf{h}_i)
        \log Pr(\mathbf{x}_i, \mathbf{h}_i \mid \boldsymbol{\theta})
    &amp; \quad &amp; \text{(7.12)}\\
 &amp;= \argmax_\boldsymbol{\theta} \sum_{i = 1}^I
      \E\left[
        \log Pr(\mathbf{x}_i, \mathbf{h}_i \mid \boldsymbol{\theta})
      \right]
    &amp; \quad &amp; \text{(7.36)}\\
 &amp;= \argmax_\boldsymbol{\theta} L(\boldsymbol{\theta})\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(L\)</span> is the log-likelihood given by</p>
<div class="math notranslate nohighlight">
\[\begin{split}L
 &amp;= -\frac{1}{2} \sum_{i = 1}^I \E\left[
      D \log(2\pi) + \log \lvert \boldsymbol{\Sigma} \rvert +
      (\mathbf{x}_i - \boldsymbol{\mu} - \boldsymbol{\Phi} \mathbf{h}_i)^\top
        \boldsymbol{\Sigma}^{-1}
        (\mathbf{x}_i - \boldsymbol{\mu} - \boldsymbol{\Phi} \mathbf{h}_i)
    \right]
    &amp; \quad &amp; \text{(7.37)}\\
 &amp;= -\frac{1}{2} \sum_{i = 1}^I \E\left[
      D \log(2\pi) + \log \lvert \boldsymbol{\Sigma} \rvert +
      \mathbf{x}_i^\top \boldsymbol{\Sigma}^{-1} \mathbf{x}_i +
      \boldsymbol{\mu}^\top \boldsymbol{\Sigma}^{-1} \boldsymbol{\mu} +
      \mathbf{h}_i^\top \boldsymbol{\Phi}^\top \boldsymbol{\Sigma}^{-1}
        \boldsymbol{\Phi} \mathbf{h}_i +
      2 \boldsymbol{\mu}^\top \boldsymbol{\Sigma}^{-1}
        \boldsymbol{\Phi} \mathbf{h}_i -
      2 \mathbf{x}_i^\top \boldsymbol{\Sigma}^{-1} \boldsymbol{\mu} -
      2 \mathbf{x}_i^\top \boldsymbol{\Sigma}^{-1}
        \boldsymbol{\Phi} \mathbf{h}_i
    \right].\end{split}\]</div>
<div class="section" id="(a)">
<h3>(a)<a class="headerlink" href="#(a)" title="Permalink to this headline">¶</a></h3>
<div class="math notranslate nohighlight">
\[\begin{split}\frac{\partial L}{\partial \boldsymbol{\mu}}
 &amp;= -\frac{1}{2} \sum_{i = 1}^I \E\left[
      2 \boldsymbol{\Sigma}^{-1} \boldsymbol{\mu} +
      2 \boldsymbol{\Sigma}^{-1} \boldsymbol{\Phi} \mathbf{h}_i -
      2 \boldsymbol{\Sigma}^{-1} \mathbf{x}_i
    \right]
    &amp; \quad &amp; \text{(C.33), (C.27), (C.28)}\\
0
 &amp;= \sum_{i = 1}^I
      -\boldsymbol{\Sigma}^{-1} \boldsymbol{\mu} -
      \boldsymbol{\Sigma}^{-1} \boldsymbol{\Phi} \E[\mathbf{h}_i] +
      \boldsymbol{\Sigma}^{-1} \mathbf{x}_i
    &amp; \quad &amp; \E \text{ is a linear operator}\\
 &amp;= \sum_{i = 1}^I
      -\boldsymbol{\Sigma}^{-1} \boldsymbol{\mu} -
      \boldsymbol{\Sigma}^{-1} \boldsymbol{\Phi} \left(
        \left(
          \boldsymbol{\Phi}^\top \boldsymbol{\Sigma}^{-1} \boldsymbol{\Phi} +
          \mathbf{I}
        \right)^{-1}
        \boldsymbol{\Phi}^\top \boldsymbol{\Sigma}^{-1}
        \left( \mathbf{x}_i - \boldsymbol{\mu} \right)
      \right) +
      \boldsymbol{\Sigma}^{-1} \mathbf{x}_i
    &amp; \quad &amp; \text{(7.35)}\\
 &amp;= \sum_{i = 1}^I
      \left(
        \boldsymbol{\Sigma}^{-1} -
        \boldsymbol{\Sigma}^{-1} \boldsymbol{\Phi} \left(
          \boldsymbol{\Phi}^\top \boldsymbol{\Sigma}^{-1} \boldsymbol{\Phi} +
          \mathbf{I}
        \right)^{-1}
        \boldsymbol{\Phi}^\top \boldsymbol{\Sigma}^{-1}
      \right) \mathbf{x}_i -
      \left(
        \boldsymbol{\Sigma}^{-1} -
        \boldsymbol{\Sigma}^{-1} \boldsymbol{\Phi} \left(
          \boldsymbol{\Phi}^\top \boldsymbol{\Sigma}^{-1} \boldsymbol{\Phi} +
          \mathbf{I}
        \right)^{-1}
        \boldsymbol{\Phi}^\top \boldsymbol{\Sigma}^{-1}
      \right) \boldsymbol{\mu}\\
 &amp;= \sum_{i = 1}^I
      \left(
        \boldsymbol{\Sigma} + \boldsymbol{\Phi} \boldsymbol{\Phi}^\top
      \right)^{-1} \mathbf{x}_i -
      \left(
        \boldsymbol{\Sigma} + \boldsymbol{\Phi} \boldsymbol{\Phi}^\top
      \right)^{-1} \boldsymbol{\mu}
    &amp; \quad &amp; \text{Sherman-Morrison-Woodbury formula}\\
\boldsymbol{\mu} &amp;= \frac{1}{I} \sum_{i = 1}^I \mathbf{x}_i\end{split}\]</div>
</div>
<div class="section" id="(b)">
<h3>(b)<a class="headerlink" href="#(b)" title="Permalink to this headline">¶</a></h3>
<div class="math notranslate nohighlight">
\[\begin{split}\frac{\partial L}{\partial \boldsymbol{\Phi}}
 &amp;= -\frac{1}{2} \sum_{i = 1}^I
      \E\left[
        2 \boldsymbol{\Sigma}^{-1} \boldsymbol{\Phi}
          \mathbf{h}_i \mathbf{h}_i^\top +
        2 \boldsymbol{\Sigma}^{-1} \boldsymbol{\mu} \mathbf{h}_i^\top -
        2 \boldsymbol{\Sigma}^{-1} \mathbf{x}_i \mathbf{h}_i^\top
      \right]
    &amp; \quad &amp; \text{(C.34), (C.29)}\\
0
 &amp;= \sum_{i = 1}^I
      -\boldsymbol{\Sigma}^{-1} \boldsymbol{\Phi}
        \E\left[ \mathbf{h}_i \mathbf{h}_i^\top \right] -
      \boldsymbol{\Sigma}^{-1} \boldsymbol{\mu}
        \E\left[ \mathbf{h}_i^\top \right] +
      \boldsymbol{\Sigma}^{-1} \mathbf{x}_i
        \E\left[ \mathbf{h}_i^\top \right]
    &amp; \quad &amp; \E \text{ is a linear operator}\\
\boldsymbol{\Phi}
 &amp;= \left(
      \sum_{i = 1}^I
        (\mathbf{x}_i - \boldsymbol{\mu}) \E\left[ \mathbf{h}_i^\top \right]
    \right)
    \left(
      \sum_{i = 1}^I \E\left[ \mathbf{h}_i \mathbf{h}_i^\top \right]
    \right)^{-1}\end{split}\]</div>
</div>
<div class="section" id="(c)">
<h3>(c)<a class="headerlink" href="#(c)" title="Permalink to this headline">¶</a></h3>
<div class="math notranslate nohighlight">
\[\begin{split}\DeclareMathOperator{\diag}{\mathrm{diag}}
\frac{\partial L}{\partial \boldsymbol{\Sigma}}
 &amp;= -\frac{1}{2} \sum_{i = 1}^I
      \E\left[
        \boldsymbol{\Sigma}^{-\top} -
        \boldsymbol{\Sigma}^{-\top}
          \left(
            \mathbf{x}_i - \boldsymbol{\mu} - \boldsymbol{\Phi} \mathbf{h}_i
          \right)
          \left(
            \mathbf{x}_i - \boldsymbol{\mu} - \boldsymbol{\Phi} \mathbf{h}_i
          \right)^\top
          \boldsymbol{\Sigma}^{-\top}
      \right]
    &amp; \quad &amp; \text{(C.38) and Matrix Cookbook (61)}\\
\boldsymbol{\Sigma}
 &amp;= \frac{1}{I} \sum_{i = 1}^I
      \E\left[
        \left(
          \mathbf{x}_i - \boldsymbol{\mu} - \boldsymbol{\Phi} \mathbf{h}_i
        \right)
        \left(
          \mathbf{x}_i - \boldsymbol{\mu} - \boldsymbol{\Phi} \mathbf{h}_i
        \right)^\top
      \right]
    &amp; \quad &amp; \E \text{ is a linear operator}\\
 &amp;= \frac{1}{I} \sum_{i = 1}^I
      (\mathbf{x}_i - \boldsymbol{\mu})
        (\mathbf{x}_i - \boldsymbol{\mu})^\top +
      \E\left[
        2 \boldsymbol{\Phi} \mathbf{h}_i \boldsymbol{\mu}^\top -
        2 \boldsymbol{\Phi} \mathbf{h}_i \mathbf{x}_i^\top +
        \boldsymbol{\Phi} \mathbf{h}_i
          \mathbf{h}_i^\top \boldsymbol{\Phi}^\top
      \right]
    &amp; \quad &amp; \text{expanded version of (7.37)}\\
 &amp;= \frac{1}{I} \sum_{i = 1}^I
      (\mathbf{x}_i - \boldsymbol{\mu})
        (\mathbf{x}_i - \boldsymbol{\mu})^\top -
      2 \boldsymbol{\Phi} \E[\mathbf{h}_i]
        \left( \mathbf{x}_i - \boldsymbol{\mu}\right)^\top +
      \boldsymbol{\Phi} \E\left[ \mathbf{h}_i \mathbf{h}_i^\top \right]
        \boldsymbol{\Phi}^\top\\
 &amp;= \frac{1}{I} \sum_{i = 1}^I
      (\mathbf{x}_i - \boldsymbol{\mu})
        (\mathbf{x}_i - \boldsymbol{\mu})^\top -
      \boldsymbol{\Phi} \E[\mathbf{h}_i]
        \left( \mathbf{x}_i - \boldsymbol{\mu} \right)^\top
    &amp; \quad &amp; \text{(b)}\\
 &amp;= \frac{1}{I} \sum_{i = 1}^I \diag\left[
      (\mathbf{x}_i - \boldsymbol{\mu})
        (\mathbf{x}_i - \boldsymbol{\mu})^\top -
      \boldsymbol{\Phi} \E[\mathbf{h}_i]
        \left( \mathbf{x}_i - \boldsymbol{\mu}\right)^\top
    \right]
    &amp; \quad &amp; \boldsymbol{\Sigma} \text{ diagonal constraint.}\end{split}\]</div>
</div>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
        <br/>
        
<div id="sourcelink">
  <a href="../../_sources/nb/computer-vision-models-learning-and-inference-prince/chapter-07.ipynb.txt"
     rel="nofollow">Source</a>
</div>
      
    </p>
    <p>
        &copy; Copyright 2013-2020, alphaXomega.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.1.2.<br/>
    </p>
  </div>
</footer>
  </body>
</html>