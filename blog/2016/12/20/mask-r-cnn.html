<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Mask R-CNN &#8212; All Things Phi</title>
    <link rel="stylesheet" href="../../../../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/my-styles.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../../../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdn.rawgit.com/mathjax/MathJax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="shortcut icon" href="../../../../_static/phi.ico"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation" href="../19/rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation.html" />
    <link rel="prev" title="Memex Prototype" href="../../../../index.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../../../../_static/js/jquery-1.11.0.min.js "></script>
<script type="text/javascript" src="../../../../_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="../../../../_static/bootstrap-3.3.7/js/bootstrap.min.js "></script>
<script type="text/javascript" src="../../../../_static/bootstrap-sphinx.js "></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../../../index.html">
          All Things Phi</a>
        <span class="navbar-text navbar-version pull-left"><b></b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../../../../index.html">Archive <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Mask R-CNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../19/rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation.html">Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../18/watertight-ray-triangle-intersection.html">Watertight Ray/Triangle Intersection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../17/understanding-deep-learning-requires-rethinking-generalization.html">Understanding Deep Learning Requires Rethinking Generalization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../16/accurate-large-minibatch-sgd-training-imagenet-in-1-hour.html">Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../15/on-large-batch-training-for-deep-learning-generalization-gap-and-sharp-minima.html">On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima</a></li>
<li class="toctree-l1"><a class="reference internal" href="../14/layer-normalization.html">Layer Normalization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../13/batch-normalization-accelerating-deep-network-training-by-reducing-internal-covariate-shift.html">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a></li>
<li class="toctree-l1"><a class="reference internal" href="../12/deep-residual-learning-for-image-recognition.html">Deep Residual Learning for Image Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../11/optimal-step-nonrigid-icp-algorithms-for-surface-registration.html">Optimal Step Nonrigid ICP Algorithms for Surface Registration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../10/delving-deep-into-rectifiers-surpassing-human-level-performance-on-imagenet-classification.html">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../09/least-squares-estimation-of-transformation-parameters-between-two-point-patterns.html">Least-Squares Estimation of Transformation Parameters Between Two Point Sets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../08/a-fast-learning-algorithm-for-deep-belief-nets.html">A Fast Learning Algorithm for Deep Belief Nets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../07/a-view-of-the-EM-algorithm-that-justifies-incremental-sparse-and-other-variants.html">A View of the EM Algorithm that Justifies Incremental, Sparse, and Other Variants</a></li>
<li class="toctree-l1"><a class="reference internal" href="../06/one-weird-trick-for-parallelizing-convolutional-neural-networks.html">One Weird Trick for Parallelizing Convolutional Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../05/exponential-family-harmoniums-with-an-application-to-information-retrieval.html">Exponential Family Harmoniums with an Application to Information Retrieval</a></li>
<li class="toctree-l1"><a class="reference internal" href="../04/pose-space-deformation-a-unified-approach-to-shape-interpolation-and-skeleton-driven-deformation.html">Pose Space Deformation: A Unified Approach to Shape Interpolation and Skeleton-Driven Deformation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02/learning-internal-representations-by-error-propagation.html">Learning Internal Representations by Error Propagation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01/structuring-a-renderer-phi-ray.html">Structuring a Renderer: <span class="math notranslate nohighlight">\(\varphi\)</span>-Ray</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11/30/information-processing-in-dynamical-systems-foundations-of-harmony-theory.html">Information Processing in Dynamical Systems: Foundations of Harmony Theory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11/29/an-introduction-to-the-conjugate-gradient-method-without-the-agonizing-pain.html">An Introduction to the Conjugate Gradient Method Without the Agonizing Pain</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11/28/a-learning-algorithm-for-boltzmann-machines.html">A Learning Algorithm for Boltzmann Machines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11/27/geometric-skinning-with-approximate-dual-quaternion-blending.html">Geometric Skinning with Approximate Dual Quaternion Blending</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11/26/the-perceptron-a-probabilistic-model-for-information-storage-and-organization-in-the-brain.html">The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11/25/the-sharpe-ratio.html">The Sharpe Ratio</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11/24/neural-networks-and-physical-systems-with-emergent-collective-computational-abilities.html">Neural Networks and Physical Systems with Emergent Collective Computational Abilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11/23/training-products-of-experts-by-minimizing-contrastive-divergence.html">Training Products of Experts by Minimizing Contrastive Divergence</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11/22/market-timing-with-candlestick-technical-analysis.html">Market Timing with Candlestick Technical Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11/21/all-that-glitters-is-not-gold-comparing-backtest-and-out-of-sample-performance-on-a-large-cohort-of-trading-algorithms.html">All that Glitters is Not Gold: Comparing Backtest and Out-of-Sample Performance on a Large Cohort of Trading Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11/20/easy-volatility-investing.html">Easy Volatility Investing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11/19/a-tutorial-on-helmholtz-machines.html">A Tutorial on Helmholtz Machines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11/18/when-do-stop-loss-rules-stop-losses.html">When Do Stop-Loss Rules Stop Losses?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11/17/a-simple-implicit-measure-of-the-effective-bid-ask-spread-in-an-efficient-market.html">A Simple Implicit Measure of the Effective Bid-Ask Spread in an Efficient Market</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11/16/asset-prices-and-trading-volume-under-fixed-transactions-costs.html">Asset Prices and Trading Volume Under Fixed Transactions Costs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11/15/maxout-networks.html">Maxout Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11/14/dropout-a-simple-way-to-prevent-neural-networks-from-overfitting.html">Dropout: A Simple Way to Prevent Neural Networks from Overfitting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11/13/dropout-training-as-adaptive-regularization.html">Dropout Training as Adaptive Regularization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11/12/model-compression.html">Model Compression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11/11/distilling-the-knowledge-in-a-neural-network.html">Distilling the Knowledge in a Neural Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11/10/do-deep-nets-really-need-to-be-deep.html">Do Deep Nets Really Need to be Deep?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11/09/efficient-backprop.html">Efficient Backprop</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11/08/stochastic-gradient-descent-tricks.html">Stochastic Gradient Descent Tricks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11/07/automatic-differentiation-in-machine-learning-a-survey.html">Automatic Differentiation in Machine Learning: A Survey</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11/06/econometric-models-of-limit-order-executions.html">Econometric Models of Limit-Order Executions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11/05/multilayer-feedforward-networks-are-universal-approximators.html">Multilayer Feedforward Networks are Universal Approximators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11/04/dendritic-computation.html">Dendritic Computation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11/03/understanding-order-flow.html">Understanding Order Flow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11/02/optimal-control-of-execution-costs.html">Optimal Control of Execution Costs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../11/01/risks-and-portfolio-decisions-involving-hedge-funds.html">Risks and Portfolio Decisions Involving Hedge Funds</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../10/30/coordinate-systems.html">Coordinate Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../10/28/hedge-funds-the-living-and-the-dead.html">Hedge Funds: The Living and the Dead</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../10/24/do-hedge-funds-have-enough-capital-a-value-at-risk-approach.html">Do Hedge Funds Have Enough Capital?  A Value-at-Risk Approach</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../10/23/characterizing-computer-performance-with-a-single-number.html">Characterizing Computer Performance with a Single Number</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../10/22/how-to-not-lie-with-statistics-the-correct-way-to-summarize-benchmark-results.html">How Not to Lie with Statistics: The Correct Way to Summarize Benchmark Results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../10/19/an-econometric-analysis-of-serial-correlation-and-illiquidity-in-hedge-fund-returns.html">An Econometric Analysis of Serial Correlation and Illiquidity in Hedge-Fund Returns</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../10/13/empirical-characteristics-of-dynamic-trading-strategies-the-case-of-hedge-funds.html">Empirical Characteristics of Dynamic Trading Strategies: The Case of Hedge Funds</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../10/06/orange-juice-and-weath.html">Orange Juice and Weather</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../10/04/the-adaptive-markets-hypothesis-market-efficiency-from-an-evolutionary-perspective.html">The Adaptive Markets Hypothesis: Market Efficiency from an Evolutionary Perspective</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../10/02/do-asset-prices-reflect-fundamentals-freshly-squeezed-evidence-from-the-oj-market.html">Do Asset Prices Reflect Fundamentals?  Freshly Squeezed Evidence from the OJ Market</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../09/30/neuroeconomics-how-neuroscience-can-inform-economics.html">Neuroeconomics: How Neuroscience Can Inform Economics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../09/28/drawing-inferences-from-statistics-based-on-multiyear-asset-returns.html">Drawing Inferences from Statistics based on Multiyear Asset Returns</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../09/26/when-are-contrarian-profits-due-to-stock-market-overreaction.html">When are Contrarian Profits Due to Stock Market Overreaction?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../09/24/profitability-of-momentum-strategies-an-evaluation-of-alternative-explanations.html">Profitability of Momentum Strategies: An Evaluation of Alternative Explanations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../09/22/the-restrictions-on-predictability-implied-by-rational-asset-pricing.html">The Restrictions on Predictability Implied by Rational Asset Pricing Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../09/20/the-myth-of-long-horizon-predictability.html">The Myth of Long-Horizon Predictability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../09/18/the-standard-error-of-regressions.html">The Standard Error of Regressions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../09/16/lets-take-the-con-out-of-econometrics.html">Let’s Take the Con Out of Econometrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../09/14/role-of-models-in-statistical-analysis.html">Role of Models in Statistical Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../09/12/the-experimental-generation-of-interpersonal-closeness-a-procedure-and-some-preliminary-findings.html">The Experimental Generation of Interpersonal Closeness: A Procedure and Some Preliminary Findings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../08/02/notes-on-tensorflow.html">Notes on TensorFlow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../08/01/tensorflow-tensorboard-and-docker.html">TensorFlow, TensorBoard, and Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../01/13/review-and-analysis-of-solutions-of-the-three-point-perspective-pose-estimation-problem.html">Review and Analysis of Solutions of the Three Point Perspective Pose Estimation Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../01/12/variational-learning-for-switching-state-space-models.html">Variational Learning for Switching State-Space Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../01/11/bayesian-face-recognition.html">Bayesian Face Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../01/10/robust-generative-subspace-modeling-the-subspace-t-distribution.html">Robust Generative Subspace Modeling: The Subspace <span class="math notranslate nohighlight">\(t\)</span> Distribution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../01/09/robust-subspace-mixture-models-using-t-distributions.html">Robust Subspace Mixture Models using <span class="math notranslate nohighlight">\(t\)</span>-distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../01/08/robust-mixture-modelling-using-the-t-distribution.html">Robust Mixture Modelling using the <span class="math notranslate nohighlight">\(t\)</span>-distribution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../01/07/mixtures-of-probabilistic-principal-component-analyzers.html">Mixtures of Probabilistic Principal Component Analysers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../01/06/the-em-algorithm-for-mixtures-of-factor-analyzers.html">The EM Algorithm for Mixtures of Factor Analyzers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../01/05/3d-live-real-time-captured-content-for-mixed-reality.html">3D Live: Real Time Captured Content for Mixed Reality</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../01/04/high-accuracy-stereo-depth-maps-using-structured-light.html">High-Accuracy Stereo Depth Maps Using Structured Light</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../01/03/simple-accurate-and-robust-projector-camera-calibration.html">Simple, Accurate, and Robust Projector-Camera Calibration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../01/02/multiresolution-gray-scale-and-rotation-invariant-texture-classification-with-local-binary-patterns.html">Multiresolution Gray Scale and Rotation Invariant Texture Classification with Local Binary Patterns</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../01/01/generative-or-discriminative-getting-the-best-of-both-worlds.html">Generative or Discriminative?  Getting the Best of Both Worlds</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/02/01/seda-an-architecture-for-well-conditioned,-scalable-internet-services.html">SEDA: An Architecture for Well-Conditioned, Scalable Internet Services</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/26/reconciling-environment-integration-and-component-independence.html">Reconciling Environment Integration and Component Independence</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/25/design-patterns-abstraction-and-reuse-of-object-oriented-design.html">Design Patterns: Abstraction and Reuse of Object-Oriented Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/24/a-guide-to-metaphorical-design.html">A Guide to Metaphorical Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/23/a-spiral-model-of-software-development-and-enhancement.html">A Spiral Model of Software Development and Enhancement</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/22/sequential-and-concurrent-object-oriented-programming.html">Sequential and Concurrent Object-Oriented Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/21/software-aging.html">Software Aging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/20/applying-design-by-contract.html">Applying “Design by Contract”</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/19/predicate-logic-for-software-engineering.html">Predicate Logic for Software Engineering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/18/active-design-reviews-principles-and-practices.html">Active Design Reviews: Principles and Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/17/a-rational-design-process-how-and-why-to-fake-it.html">A Rational Design Process: How and Why to Fake It</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/16/the-modular-structure-of-complex-systems.html">The Modular Structure of Complex Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/15/abstract-types-defined-as-classes-of-variables.html">Abstract Types Defined as Classes of Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/14/use-of-abstract-interfaces-in-the-development-of-software-for-embedded-computer-systems.html">Use of Abstract Interfaces in the Development of Software for Embedded Computer Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/13/the-influence-of-software-structure-on-reliability.html">The Influence of Software Structure on Reliability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/12/response-to-detected-errors-in-well-structured-programs.html">Response to Detected Errors in Well-Structured Programs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/11/the-use-of-abstract-data-types-to-simplify-program-modifications.html">The Use of Abstract Data Types to Simplify Program Modifications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/10/use-of-the-concept-of-transparency-in-the-design-of-hierarchically-structured-systems.html">Use of the Concept of Transparency in the Design of Hierarchically Structured Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/09/designing-software-for-ease-of-extension-and-contraction.html">Designing Software for Ease of Extension and Contraction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/08/on-the-design-and-development-of-program-families.html">On the Design and Development of Program Families</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/07/on-the-criteria-to-be-used-in-decomposing-systems-into-modules.html">On the Criteria to be Used in Decomposing Systems into Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/06/a-technique-for-software-module-specification-with-examples.html">A Technique for Software Module Specification with Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/05/information-distribution-aspects-of-design-methodology.html">Information Distribution Aspects of Design Methodology</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/04/a-model-of-large-program-development.html">A Model of Large Program Development</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/03/architectural-styles-and-the-design-of-network-based-software-architectures.html">Architectural Styles and the Design of Network-based Software Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/02/design-of-design.html">Design of Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/01/notes-on-the-synthesis-of-form.html">Notes on the Synthesis of Form</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/27/sphinx-on-github-pages.html">Sphinx on GitHub Pages</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/26/blogging-with-docker.html">Blogging with Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/25/typical-mercurial-usage.html">Typical Mercurial Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/24/profiling-on-linux.html">Profiling on Linux</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/23/trading-cryptocurrencies.html">Trading Cryptocurrencies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/22/notes-on-software-design.html">Notes on Software Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/21/notes-on-scraping-together-a-heterogeneous-system.html">Notes on Scraping Together a Heterogeneous System</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/20/transfer-media-files-to-mobile-device-via-vlc.html">Transfer Media Files to Mobile Device via VLC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/19/style-lessons-in-clarity-and-grace.html">Style: Lessons in Clarity and Grace</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/18/the-science-of-scientific-writing.html">The Science of Scientific Writing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/17/collection-of-notes-on-research.html">Collection of Notes on Research</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/16/typical-ffmpeg-usage.html">Typical FFmpeg Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/15/generate-svg-graphics.html">Generate SVG Graphics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/14/blogging-with-restructuredtext-a-google-domain-and-sphinx.html">Blogging with RestructuredText, a Google Domain, and Sphinx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/13/set-up-android-development-environment.html">Set Up Android Development Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/12/svegan-lifestyle.html">Svegan Lifestyle</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/11/set-up-system-programming-environment.html">Set Up System Programming Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/10/the-rise-and-fall-of-react-flux-redux-and-cycle.html">The Rise and Fall of React, Flux, Redux, and Cycle</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/09/install-graphics-and-compute-linux-mint.html">Install Graphics and Compute on Linux Mint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/08/set-up-web-development-environment.html">Set Up Web Development Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/07/vfio-tips-and-tricks.html">VFIO Tips and Tricks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/06/options-trading.html">Options Trading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/05/assimp-mesh-loader.html">Assimp Mesh Loader</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/04/set-up-data-analysis-environment.html">Set Up Data Analysis Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/03/install-nvidia-drivers-on-linux-mint.html">Install Nvidia Drivers on Linux Mint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/02/blogging-with-restructuredtext-a-google-domain-and-pelican.html">Blogging with RestructuredText, a Google Domain, and Pelican</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/01/linux-mint-installation.html">Linux Mint Installation</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../nb/an-invitation-to-3d-vision-msks/index.html">An Invitation to 3-D Vision - Ma, Soatto, Kosecka, and Sastry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nb/complete-musician-laitz/index.html">The Complete Musician: An Integrated Approach to Tonal Theory, Analysis, and Listening - Laitz</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nb/computer-science-theory-for-the-information-age-hk/index.html">Computer Science Theory for the Information Age - Hopcroft &amp; Kannan</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nb/computer-vision-models-learning-and-inference-prince/index.html">Computer Vision: Models, Learning, and Inference - Prince</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nb/creativity-nlph/index.html">Creativity - NLPH</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nb/differential-geometry-from-a-graphics-perspective-nlph/index.html">Differential Geometry from a Graphics Perspective - NLPH</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nb/fundamentals-of-electric-circuits-as/index.html">Fundamentals of Electric Circuits - Alexander &amp; Sadiku</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nb/linear-programming-vanderbei/index.html">Linear Programming - Vanderbei</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nb/multiple-view-geometry-hz/index.html">Multiple View Geometry in Computer Vision - Hartley &amp; Zisserman</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nb/numerical-methods-for-unconstrained-optimization-and-nonlinear-equations-ds/index.html">Numerical Methods for Unconstrained Optimization and Nonlinear Equations - Dennis &amp; Schnabel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nb/pattern-recognition-and-machine-learning-bishop/index.html">Pattern Recognition and Machine Learning - Bishop</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nb/reinforcement-learning-sb/index.html">Reinforcement Learning: An Introduction - Sutton &amp; Barto</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nb/stat-labs-ns/index.html">Stat Labs - Nolan &amp; Speed</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Mask R-CNN</a><ul>
<li><a class="reference internal" href="#motivation-s">Motivation(s)</a></li>
<li><a class="reference internal" href="#proposed-solution-s">Proposed Solution(s)</a></li>
<li><a class="reference internal" href="#evaluation-s">Evaluation(s)</a></li>
<li><a class="reference internal" href="#future-direction-s">Future Direction(s)</a></li>
<li><a class="reference internal" href="#question-s">Question(s)</a></li>
<li><a class="reference internal" href="#analysis">Analysis</a></li>
<li><a class="reference internal" href="#notes">Notes</a><ul>
<li><a class="reference internal" href="#fully-convolutional-networks">Fully Convolutional Networks</a></li>
<li><a class="reference internal" href="#deconvolutional-networks">Deconvolutional Networks</a></li>
<li><a class="reference internal" href="#feature-pyramid-network">Feature Pyramid Network</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
  <li>
    <a href="../../../../index.html" title="Previous Chapter: Memex Prototype"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; Memex Prototype</span>
    </a>
  </li>
  <li>
    <a href="../19/rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation.html" title="Next Chapter: Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">Rich Feature ... &raquo;</span>
    </a>
  </li>
              
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../../../../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <div class="section" id="mask-r-cnn">
<h1>Mask R-CNN<a class="headerlink" href="#mask-r-cnn" title="Permalink to this headline">¶</a></h1>
<div class="section" id="motivation-s">
<h2>Motivation(s)<a class="headerlink" href="#motivation-s" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="../19/rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation.html"><span class="doc">R-CNN</span></a>
is the leading framework for object detection where the goal is to classify
individual objects and localize each using a bounding box.  A related task is
semantic segmentation where the solution consists of classifying each pixel into
a fixed set of categories without differentiating object instances.  Existing
solutions start from per-pixel classification results and attempt to cut the
pixels of the same category into different instances.  Specifically, these
solutions use a per-pixel softmax and a multinomial cross-entropy loss.  Alas,
these segmentation-first exhibits systematic errors on overlapping instances and
creates spurious edges.</p>
</div>
<div class="section" id="proposed-solution-s">
<h2>Proposed Solution(s)<a class="headerlink" href="#proposed-solution-s" title="Permalink to this headline">¶</a></h2>
<p>The authors extend Faster R-CNN by adding a branch for predicting segmentation
masks on each Region of Interest (RoI), in parallel with the existing branch for
classification and bounding box regression.  The mask branch is a small FCN
applied to each RoI, predicting a segmentation mask in a pixel-to-pixel manner.
This instance-first strategy decouples mask and class prediction: predict a
binary mask for each class independently, without competition among classes, and
rely on the network’s RoI classification branch to predict the category.</p>
<p>The mask branch has a <span class="math notranslate nohighlight">\(Km^2\)</span>-dimensional output for each RoI, which
encodes <span class="math notranslate nohighlight">\(K\)</span> binary masks of solution <span class="math notranslate nohighlight">\(m \times m\)</span>, one for each of
the <span class="math notranslate nohighlight">\(K\)</span> classes.  Applying a per-pixel sigmoid yields the average binary
cross-entropy loss <span class="math notranslate nohighlight">\(L_{\text{mask}}\)</span>.  For an RoI associated with
ground-truth class <span class="math notranslate nohighlight">\(k\)</span>, the loss <span class="math notranslate nohighlight">\(L_{\text{mask}}\)</span> is only defined
on the :math:<a href="#id1"><span class="problematic" id="id2">`</span></a>k`th mask; other mask outputs do not contribute to the loss.
Unlike the previous methods that resort to fully-connected layers for mask
prediction, the proposed fully convolutional mask representation more accurately
extracts the spatial structure of an input object.</p>
<p>Recall that RoIPool first quantizes the RoI to the discrete granularity of the
feature map, and subsequently subdivide it into spatial bins.  These
quantizations introduce misalignments between the RoI and the extracted
features, and have negligible effects on image classification, which is robust
to small translations.  However, it has a large negative effect on predicting
pixel-accurate masks.  Instead of performing any spatial quantization, the
authors propose RoIAlign, a uniform sampling strategy.  RoIAlign uses bilinear
interpolation to compute the exact values of the input features at four
regularly sampled locations in each RoI bin, and aggregate the result (e.g.
max, average).</p>
</div>
<div class="section" id="evaluation-s">
<h2>Evaluation(s)<a class="headerlink" href="#evaluation-s" title="Permalink to this headline">¶</a></h2>
<p>The authors evaluated their model on the COCO dataset as well as the Cityscapes
dataset.  Their model took approximately two days to train on a single eight
GPU machine where each frame took 200ms to process on a GPU.  They beat
state-of-the-art in each case without using extra bells and whistles e.g.
multi-scale train and test, horizontal flip test, online hard example mining.</p>
<p>Their ablation experiments reveal that once an instance has been classified as a
whole (by the box branch), it is sufficient to predict a binary mask without
concern for the categories, which results in an easier model to train.  They
also uncovered a domain-shift on the val and test set of the Cityscapes dataset.
To reduce the within-category bias, they use COCO pre-training.</p>
</div>
<div class="section" id="future-direction-s">
<h2>Future Direction(s)<a class="headerlink" href="#future-direction-s" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>The authors emphasized RoI quantization plays a greater role than the sampling
strategy itself.  Perhaps the feature map is already quantized to some extent
such that sampling plays a minor role?</p></li>
<li><p>How would the proposed keypoint model perform when trained on the data used
to train the Kinect’s random forest model?</p></li>
</ul>
</div>
<div class="section" id="question-s">
<h2>Question(s)<a class="headerlink" href="#question-s" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>For human pose estimation on the COCO keypoint dataset, the authors view each
keypoint as a one-hot binary mask and predicted <span class="math notranslate nohighlight">\(K\)</span> masks, one for each
of the <span class="math notranslate nohighlight">\(K\)</span> keypoint types.  Their unified model can simultaneously
predict boxes, segments, and keypoints while running at 5 FPS.  Do the
keypoint labels denote specific body parts e.g. left shoulder, right elbow?</p></li>
</ul>
</div>
<div class="section" id="analysis">
<h2>Analysis<a class="headerlink" href="#analysis" title="Permalink to this headline">¶</a></h2>
<p><a class="bibtex reference internal" href="#he2017mask" id="id3">[HGDollarG17]</a> demonstrated the effectiveness of network branch heads as a
default strategy to handle a new task without domain knowledge.  Their
experiments reveal that quantization is typically inferior to sampling, and
competitive loss functions may introduce undesirable optimization side effects
compared to using individual loss functions.  However, they did not provide
enough evidence for their verdict of different sampling strategies being
ineffective.  Perhaps this is due to some issues further up the pipeline akin to
the Cityscapes dataset implicit bias?</p>
</div>
<div class="section" id="notes">
<h2>Notes<a class="headerlink" href="#notes" title="Permalink to this headline">¶</a></h2>
<div class="section" id="fully-convolutional-networks">
<h3>Fully Convolutional Networks<a class="headerlink" href="#fully-convolutional-networks" title="Permalink to this headline">¶</a></h3>
<p>Each layer of data in a convnet has dimensions <span class="math notranslate nohighlight">\(h \times w \times d\)</span>.
The first layer is the image of size <span class="math notranslate nohighlight">\(h \times w\)</span> and <span class="math notranslate nohighlight">\(d\)</span> color
channels.  Given <span class="math notranslate nohighlight">\(\mathbf{x}_{ij}\)</span> for the data vector at location
<span class="math notranslate nohighlight">\((i, j)\)</span> in a particular layer and <span class="math notranslate nohighlight">\(\mathbf{y}_{ij}\)</span> for the
following layer,</p>
<div class="math notranslate nohighlight">
\[\mathbf{y}_{ij} = f_{ks} \left(
                    \left\{
                      \mathbf{x}_{si + \delta i, sj + \delta j}
                    \right\}_{0 \leq \delta i, \delta j \leq k}
                  \right)\]</div>
<p>where <span class="math notranslate nohighlight">\(k\)</span> is the kernel size, <span class="math notranslate nohighlight">\(s\)</span> is the stride or subsampling
factor, and <span class="math notranslate nohighlight">\(f_{ks}\)</span> determines the layer type e.g. a matrix
multiplication for convolution or average pooling, a spatial max for max
pooling, or an elementwise nonlinearity for an activation function.</p>
<p>A network with only layers of the functional form</p>
<div class="math notranslate nohighlight">
\[f_{ks} \circ g_{k's'} = \left( f \circ g \right)_{f' + (k - 1) s', ss'}\]</div>
<p>computes a nonlinear filter a.k.a. deep filter or a fully convolutional network
(FCN).  If a FCN is composed with a real-valued loss function defined over the
spatial dimensions of the final layer, <a class="bibtex reference internal" href="#long2015fully" id="id4">[LSD15]</a> observed that its
gradient will be a sum over the gradients of each of its spatial components.
Hence stochastic gradient descent on whole images will be the same as stochastic
gradient descent taking all of the final layer receptive fields as a minibatch.</p>
<p>Since receptive fields overlap significantly, the feedforward and
backpropagation computation are amortized over the entire image.  Thus yielding
approximately <span class="math notranslate nohighlight">\(5x\)</span> faster training and inference.  Furthermore,
<a class="reference internal" href="../12/deep-residual-learning-for-image-recognition.html"><span class="doc">casting fully connected layers as convolutions with kernels</span></a>
enables the neural network to take inputs of arbitrary dimension and outputs
coarse classification maps.</p>
<p>To connect coarse outputs to dense pixels, the authors observed that upsampling
with factor <span class="math notranslate nohighlight">\(f\)</span> is convolution with a fractional input stride of
<span class="math notranslate nohighlight">\(1 / f\)</span>.  As long as <span class="math notranslate nohighlight">\(f\)</span> is integral, the upsampling process reduces
to a backwards convolution (a.k.a. deconvolution) with an output stride of
<span class="math notranslate nohighlight">\(f\)</span>.  This allows the deconvolution filters to be learned by
backpropagation from the pixelwise loss.  These intermediate upsampling layers
are initialized to bilinear upsampling, and then learned.  Only the final layer
deconvolutional filters are fixed to bilinear interpolation.</p>
<p>Their experiments indicate that the faster fully convolutional training has
similar convergence rates to slower patchwise training.  To achieve higher
accuracy, the authors added skips that combine the final prediction layer with
finer layers.  This nonlinear feature hierarchy (a.k.a. deep jet) enables the
model to fuse coarse global semantic structures with local appearance
information.</p>
<p>More concretely, they generate upsampled predictions called FCN-<span class="math notranslate nohighlight">\(2^n\)</span>
where <span class="math notranslate nohighlight">\(n\)</span> is the level of pooling.  Suppose <span class="math notranslate nohighlight">\(m = 5\)</span> is the final
pooling layer.  The base FCN-<span class="math notranslate nohighlight">\(2^m\)</span> contains no deconvolutional filters.
The other FCNs are constructed as follows:</p>
<ol class="arabic simple">
<li><p>Add a <span class="math notranslate nohighlight">\(1 \times 1\)</span> convolutional layer on top of the
<span class="math notranslate nohighlight">\(n^\mathrm{th}\)</span> pooling layer to produce additional class predictions.</p></li>
<li><p>Add a <span class="math notranslate nohighlight">\(2^{m - n}x\)</span> bilinear upsampling layer for conv7’s prediction
outputs.</p></li>
<li><p>For each pooling layer <span class="math notranslate nohighlight">\(i\)</span> where <span class="math notranslate nohighlight">\(n &lt; i &lt; m\)</span>, add a
<span class="math notranslate nohighlight">\(2^{i - n}x\)</span> bilinear upsampling layer for pooling layer <span class="math notranslate nohighlight">\(i\)</span>’s
prediction outputs resulting from step (1).</p></li>
<li><p>These predictions are summed, and the result is upsampled back to the input
image size.</p></li>
</ol>
<p>Some interesting points from their experiments are:</p>
<ul class="simple">
<li><p>Adding more skips at pool2 and pool1 did not yield significant improvements.</p></li>
<li><p>Shift-and-stitch (a.k.a. filter rarefaction) trick is worse than the layer
fusion.</p></li>
<li><p>Patch sampling images did not converge any faster than whole image training.</p></li>
<li><p>Class balancing is unnecessary even when training images consists of
<span class="math notranslate nohighlight">\(3 / 4\)</span> background.</p></li>
<li><p>Partially decorrelating pixels (e.g. jittering, randomly mirroring) did not
help the training nor accuracy.</p></li>
</ul>
<p>The authors mentioned max fusion made learning difficult due to gradient
switching.  If the fusion used the average of the predictions, would the
learning or accuracy change significantly?  Another point the authors should
have explored further is why learning large filters is difficult when pool5 has
a stride of one.</p>
<p>Even though FCNs take inputs of arbitrary dimensions, the network still operates
via a fixed-size receptive field <a class="bibtex reference internal" href="#noh2015learning" id="id5">[NHH15]</a>.  Objects that are
substantially larger or smaller than the receptive field may be fragmented or
mislabeled.  Large objects are only captured by local information, and small
objects are often ignored and classified as background.  Furthermore, the
detailed structures of an object are often lost or smoothed due to the coarse
label map.</p>
</div>
<div class="section" id="deconvolutional-networks">
<h3>Deconvolutional Networks<a class="headerlink" href="#deconvolutional-networks" title="Permalink to this headline">¶</a></h3>
<p>An extension of FCNs that mitigates the foregoing limitations is a deep
deconvolutional network <a class="bibtex reference internal" href="#noh2015learning" id="id6">[NHH15]</a>.  Given a generic convolutional
network (e.g. VGG16) with its last classification layer removed, one would first
convert it to a FCN.  The extracted features are sent to a generator that
produces a probability map indicating the likelihood of each pixel belonging to
one of the predefined classes.  The generator mirrors the structure of the
convolutional network using ReLUs, unpooling, and deconvolutions.  These two
networks together form a deconvolutional network.</p>
<p>The unpooling layer performs the reverse operation of pooling to reconstruct the
original pooled location of the activations.  This entails recording the
locations of maximum activations selected during pooling operation in switch
variables.  In a sense, unpooling reconstructs example-specific detailed
structures by tracing the original locations with strong activations back to
image space in finer resolutions.</p>
<p>The proposed deconvolutional layer associates a single input activation with
multiple outputs.  The enlarged activation map is cropped to match the size of
the preceding unpooling layer’s output map.  Complementary to unpooling,
deconvolutions exhibit class-specific shapes because activations close to the
target classes are amplified while noisy activations from other regions are
suppressed.  However, the term deconvolution is a misnomer.  Recall that a
convolution connects multiple input activations within a filter window to a
single activation, which can be reformulated as a sparse matrix
<span class="math notranslate nohighlight">\(\mathbf{C}\)</span>.  Although inefficient, the desired deconvolutional layer can
be emulated via a matrix multiplication with <span class="math notranslate nohighlight">\(\mathbf{C}^\top\)</span>
<a class="bibtex reference internal" href="#dumoulin2016guide" id="id7">[DV16]</a>.  Therefore, a deconvolutional layer is actually a
transposed convolutional layer.</p>
<p>While the idea of a deconvolutional network is quite elegant, training it
entails a set of hacks.  <a class="bibtex reference internal" href="#noh2015learning" id="id8">[NHH15]</a> applied the network to each
candidate object proposals extracted from the image.  The outputs of all
proposals are aggregated in image space e.g. pixel-wise maximum, average.  Note
that the proposals are processed in decreasing order of their sizes.</p>
<p>The network initially needed ground truth annotations to crop the object
instances.  However, once the network has been sufficiently trained, object
proposals could be used directly.  It is unclear why the authors didn’t explore
training purely the deconvolutional section of the network with the outputs of
an <a class="reference internal" href="../19/rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation.html"><span class="doc">R-CNN</span></a>.
Furthermore, the experimental findings that fully-connected CRF postprocessing
of the output maps is debatable.  A mere 1% improvement for such a complicated
add-on method conflicts with the unified deep learning methodology.</p>
</div>
<div class="section" id="feature-pyramid-network">
<h3>Feature Pyramid Network<a class="headerlink" href="#feature-pyramid-network" title="Permalink to this headline">¶</a></h3>
<p>Recall that an image pyramid (mipmap) is a standard solution in computer vision
for handling objects at vastly different scales.  This concept is utilized in
the foregoing proposals in some form.  FCNs sum partial scores for each category
over multiple scales to compute semantic segmentations.  <a class="reference internal" href="../19/rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation.html"><span class="doc">SSD</span></a>
uses featurized mipmaps, but does not reuse the multi-scale feature maps from
different layers computed in the forward pass.  It instead computes new layers
and predicts objects at multiple layers of the feature hierarchy without
combining features or scores.  In an attempt to reuse the already computed
featurized mipmaps, several scale-invariant frameworks have been proposed
(<a class="bibtex reference internal" href="#pinheiro2016learning" id="id9">[PLCDollar16]</a>) with the latest being feature pyramid network
(FPN) <a class="bibtex reference internal" href="#lin2017feature" id="id10">[LDollarG+17]</a>.</p>
<p>A FPN augments an existing network (e.g. ResNet) with bottom-up pathways,
top-down pathways, and lateral connections.  Recall that during the feedforward
computation, many layers produce output maps of the same size.  Treat these
layers as part of the same network stage.</p>
<p>For each network stage, the bottom-up pathway defines a pyramid level as the
output of the last layer of that stage.  This design assumes the deepest layer
of each stage contains the strongest features.  However, for networks like
ResNet, the authors avoid constructing a pyramid level for the first stage of
ResNet due to its large memory footprint.  To incorporate semantically stronger
features, the authors define a top-down pathway that upsamples feature maps from
higher pyramid levels.  These upsampled maps are further refined with features
from the bottom-up pathway via lateral connections.  The authors construct a
FPN as follows:</p>
<ol class="arabic simple">
<li><p>Given a feature map at any stage, augment that map’s filter (channel)
dimension via a <span class="math notranslate nohighlight">\(1 \times 1\)</span> conv layer.  Denote this as the top
layer.</p></li>
<li><p>The layer below that (the bottom layer) has some size and filter dimension.
The top layer is upsampled (e.g. nearest neighbor) to match the bottom
layer’s size.</p></li>
<li><p>The bottom layer undergoes <span class="math notranslate nohighlight">\(1 \times 1\)</span> convolution to match the top
layer’s filter dimension.</p></li>
<li><p>The two layers are element-wise added.</p></li>
</ol>
<p>The option of fixing the filter dimension enables all levels of the pyramid to
use shared classifiers/regressors as in a traditional featurized image pyramid.
To reduce the aliasing effect of upsampling, each merged map undergoes a
<span class="math notranslate nohighlight">\(3 \times 3\)</span> convolution.</p>
<p>The authors demonstrate the effectiveness of FPN via replacing the multiscale
features of <a class="reference internal" href="../19/rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation.html"><span class="doc">RPN, Fast R-CNN</span></a>,
and DeepMask segmentation with the FPN.  One confusing concept the experiments
did not clarify is the pixel mask.  A pixel mask is a set of classifiers
connected to each element of the previous layer <a class="bibtex reference internal" href="#pinheiro2015learning" id="id11">[PCDollar15]</a>.
Given <span class="math notranslate nohighlight">\(h \times w\)</span> pixel classifiers, each is responsible for indicating
whether a given pixel belongs to the object in the center of the patch.  Each of
the classifiers can be locally connected or fully connected <a class="bibtex reference internal" href="#pinheiro2015learning" id="id12">[PCDollar15]</a>.
The former limits each classifier to a partial view of the object while the
latter results in a massive number of redundant parameters.  The authors’
solution is to decompose the classification layer into two linear layers with no
non-linearity in between.  This low-rank approximation enables each pixel
classifier in the output plane to utilize information contained in the entire
feature map, and thus have a complete view of the object.  The mask is still
for a single object even when multiple objects are present.</p>
<p>One question the paper did not cover is how the effective depth of each pyramid
level affects the accuracy.  Instead of downsampling the finer layer, would
upsampling along the filter dimension yield higher accuracy?  Another topic to
explore is visualizing the feature maps given an image.  Since FPN is supposed
to be an image pyramid, the different levels should have some distinct visual
features.</p>
<p class="rubric">References</p>
<p id="bibtex-bibliography-blog/2016/12/20/mask-r-cnn-0"><dl class="citation">
<dt class="bibtex label" id="dumoulin2016guide"><span class="brackets"><a class="fn-backref" href="#id7">DV16</a></span></dt>
<dd><p>Vincent Dumoulin and Francesco Visin. A guide to convolution arithmetic for deep learning. <em>arXiv preprint arXiv:1603.07285</em>, 2016.</p>
</dd>
<dt class="bibtex label" id="he2017mask"><span class="brackets"><a class="fn-backref" href="#id3">HGDollarG17</a></span></dt>
<dd><p>Kaiming He, Georgia Gkioxari, Piotr Dollár, and Ross Girshick. Mask r-cnn. In <em>Proceedings of the IEEE international conference on computer vision</em>, 2961–2969. 2017.</p>
</dd>
<dt class="bibtex label" id="lin2017feature"><span class="brackets"><a class="fn-backref" href="#id10">LDollarG+17</a></span></dt>
<dd><p>Tsung-Yi Lin, Piotr Dollár, Ross Girshick, Kaiming He, Bharath Hariharan, and Serge Belongie. Feature pyramid networks for object detection. In <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em>, 2117–2125. 2017.</p>
</dd>
<dt class="bibtex label" id="long2015fully"><span class="brackets"><a class="fn-backref" href="#id4">LSD15</a></span></dt>
<dd><p>Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully convolutional networks for semantic segmentation. In <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em>, 3431–3440. 2015.</p>
</dd>
<dt class="bibtex label" id="noh2015learning"><span class="brackets">NHH15</span><span class="fn-backref">(<a href="#id5">1</a>,<a href="#id6">2</a>,<a href="#id8">3</a>)</span></dt>
<dd><p>Hyeonwoo Noh, Seunghoon Hong, and Bohyung Han. Learning deconvolution network for semantic segmentation. In <em>Proceedings of the IEEE International Conference on Computer Vision</em>, 1520–1528. 2015.</p>
</dd>
<dt class="bibtex label" id="pinheiro2015learning"><span class="brackets">PCDollar15</span><span class="fn-backref">(<a href="#id11">1</a>,<a href="#id12">2</a>)</span></dt>
<dd><p>Pedro O Pinheiro, Ronan Collobert, and Piotr Dollár. Learning to segment object candidates. In <em>Advances in Neural Information Processing Systems</em>, 1990–1998. 2015.</p>
</dd>
<dt class="bibtex label" id="pinheiro2016learning"><span class="brackets"><a class="fn-backref" href="#id9">PLCDollar16</a></span></dt>
<dd><p>Pedro O Pinheiro, Tsung-Yi Lin, Ronan Collobert, and Piotr Dollár. Learning to refine object segments. In <em>European Conference on Computer Vision</em>, 75–91. Springer, 2016.</p>
</dd>
</dl>
</p>
</div>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
        <br/>
        
<div id="sourcelink">
  <a href="../../../../_sources/blog/2016/12/20/mask-r-cnn.rst.txt"
     rel="nofollow">Source</a>
</div>
      
    </p>
    <p>
        &copy; Copyright 2013-2020, alphaXomega.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.1.2.<br/>
    </p>
  </div>
</footer>
  </body>
</html>