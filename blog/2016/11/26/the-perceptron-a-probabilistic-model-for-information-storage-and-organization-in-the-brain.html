<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain &#8212; All Things Phi</title>
    <link rel="stylesheet" href="../../../../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/my-styles.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../../../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdn.rawgit.com/mathjax/MathJax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="shortcut icon" href="../../../../_static/phi.ico"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="The Sharpe Ratio" href="../25/the-sharpe-ratio.html" />
    <link rel="prev" title="Geometric Skinning with Approximate Dual Quaternion Blending" href="../27/geometric-skinning-with-approximate-dual-quaternion-blending.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../../../../_static/js/jquery-1.11.0.min.js "></script>
<script type="text/javascript" src="../../../../_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="../../../../_static/bootstrap-3.3.7/js/bootstrap.min.js "></script>
<script type="text/javascript" src="../../../../_static/bootstrap-sphinx.js "></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../../../index.html">
          All Things Phi</a>
        <span class="navbar-text navbar-version pull-left"><b></b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../../../../index.html">Archive <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../12/20/mask-r-cnn.html">Mask R-CNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../12/19/rich-feature-hierarchies-for-accurate-object-detection-and-semantic-segmentation.html">Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../12/18/watertight-ray-triangle-intersection.html">Watertight Ray/Triangle Intersection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../12/17/understanding-deep-learning-requires-rethinking-generalization.html">Understanding Deep Learning Requires Rethinking Generalization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../12/16/accurate-large-minibatch-sgd-training-imagenet-in-1-hour.html">Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../12/15/on-large-batch-training-for-deep-learning-generalization-gap-and-sharp-minima.html">On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../12/14/layer-normalization.html">Layer Normalization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../12/13/batch-normalization-accelerating-deep-network-training-by-reducing-internal-covariate-shift.html">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../12/12/deep-residual-learning-for-image-recognition.html">Deep Residual Learning for Image Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../12/11/optimal-step-nonrigid-icp-algorithms-for-surface-registration.html">Optimal Step Nonrigid ICP Algorithms for Surface Registration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../12/10/delving-deep-into-rectifiers-surpassing-human-level-performance-on-imagenet-classification.html">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../12/09/least-squares-estimation-of-transformation-parameters-between-two-point-patterns.html">Least-Squares Estimation of Transformation Parameters Between Two Point Sets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../12/08/a-fast-learning-algorithm-for-deep-belief-nets.html">A Fast Learning Algorithm for Deep Belief Nets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../12/07/a-view-of-the-EM-algorithm-that-justifies-incremental-sparse-and-other-variants.html">A View of the EM Algorithm that Justifies Incremental, Sparse, and Other Variants</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../12/06/one-weird-trick-for-parallelizing-convolutional-neural-networks.html">One Weird Trick for Parallelizing Convolutional Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../12/05/exponential-family-harmoniums-with-an-application-to-information-retrieval.html">Exponential Family Harmoniums with an Application to Information Retrieval</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../12/04/pose-space-deformation-a-unified-approach-to-shape-interpolation-and-skeleton-driven-deformation.html">Pose Space Deformation: A Unified Approach to Shape Interpolation and Skeleton-Driven Deformation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../12/02/learning-internal-representations-by-error-propagation.html">Learning Internal Representations by Error Propagation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../12/01/structuring-a-renderer-phi-ray.html">Structuring a Renderer: <span class="math notranslate nohighlight">\(\varphi\)</span>-Ray</a></li>
<li class="toctree-l1"><a class="reference internal" href="../30/information-processing-in-dynamical-systems-foundations-of-harmony-theory.html">Information Processing in Dynamical Systems: Foundations of Harmony Theory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../29/an-introduction-to-the-conjugate-gradient-method-without-the-agonizing-pain.html">An Introduction to the Conjugate Gradient Method Without the Agonizing Pain</a></li>
<li class="toctree-l1"><a class="reference internal" href="../28/a-learning-algorithm-for-boltzmann-machines.html">A Learning Algorithm for Boltzmann Machines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../27/geometric-skinning-with-approximate-dual-quaternion-blending.html">Geometric Skinning with Approximate Dual Quaternion Blending</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain</a></li>
<li class="toctree-l1"><a class="reference internal" href="../25/the-sharpe-ratio.html">The Sharpe Ratio</a></li>
<li class="toctree-l1"><a class="reference internal" href="../24/neural-networks-and-physical-systems-with-emergent-collective-computational-abilities.html">Neural Networks and Physical Systems with Emergent Collective Computational Abilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../23/training-products-of-experts-by-minimizing-contrastive-divergence.html">Training Products of Experts by Minimizing Contrastive Divergence</a></li>
<li class="toctree-l1"><a class="reference internal" href="../22/market-timing-with-candlestick-technical-analysis.html">Market Timing with Candlestick Technical Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../21/all-that-glitters-is-not-gold-comparing-backtest-and-out-of-sample-performance-on-a-large-cohort-of-trading-algorithms.html">All that Glitters is Not Gold: Comparing Backtest and Out-of-Sample Performance on a Large Cohort of Trading Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../20/easy-volatility-investing.html">Easy Volatility Investing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../19/a-tutorial-on-helmholtz-machines.html">A Tutorial on Helmholtz Machines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../18/when-do-stop-loss-rules-stop-losses.html">When Do Stop-Loss Rules Stop Losses?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../17/a-simple-implicit-measure-of-the-effective-bid-ask-spread-in-an-efficient-market.html">A Simple Implicit Measure of the Effective Bid-Ask Spread in an Efficient Market</a></li>
<li class="toctree-l1"><a class="reference internal" href="../16/asset-prices-and-trading-volume-under-fixed-transactions-costs.html">Asset Prices and Trading Volume Under Fixed Transactions Costs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../15/maxout-networks.html">Maxout Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../14/dropout-a-simple-way-to-prevent-neural-networks-from-overfitting.html">Dropout: A Simple Way to Prevent Neural Networks from Overfitting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../13/dropout-training-as-adaptive-regularization.html">Dropout Training as Adaptive Regularization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../12/model-compression.html">Model Compression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../11/distilling-the-knowledge-in-a-neural-network.html">Distilling the Knowledge in a Neural Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../10/do-deep-nets-really-need-to-be-deep.html">Do Deep Nets Really Need to be Deep?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../09/efficient-backprop.html">Efficient Backprop</a></li>
<li class="toctree-l1"><a class="reference internal" href="../08/stochastic-gradient-descent-tricks.html">Stochastic Gradient Descent Tricks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../07/automatic-differentiation-in-machine-learning-a-survey.html">Automatic Differentiation in Machine Learning: A Survey</a></li>
<li class="toctree-l1"><a class="reference internal" href="../06/econometric-models-of-limit-order-executions.html">Econometric Models of Limit-Order Executions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../05/multilayer-feedforward-networks-are-universal-approximators.html">Multilayer Feedforward Networks are Universal Approximators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../04/dendritic-computation.html">Dendritic Computation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../03/understanding-order-flow.html">Understanding Order Flow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02/optimal-control-of-execution-costs.html">Optimal Control of Execution Costs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01/risks-and-portfolio-decisions-involving-hedge-funds.html">Risks and Portfolio Decisions Involving Hedge Funds</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../10/30/coordinate-systems.html">Coordinate Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../10/28/hedge-funds-the-living-and-the-dead.html">Hedge Funds: The Living and the Dead</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../10/24/do-hedge-funds-have-enough-capital-a-value-at-risk-approach.html">Do Hedge Funds Have Enough Capital?  A Value-at-Risk Approach</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../10/23/characterizing-computer-performance-with-a-single-number.html">Characterizing Computer Performance with a Single Number</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../10/22/how-to-not-lie-with-statistics-the-correct-way-to-summarize-benchmark-results.html">How Not to Lie with Statistics: The Correct Way to Summarize Benchmark Results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../10/19/an-econometric-analysis-of-serial-correlation-and-illiquidity-in-hedge-fund-returns.html">An Econometric Analysis of Serial Correlation and Illiquidity in Hedge-Fund Returns</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../10/13/empirical-characteristics-of-dynamic-trading-strategies-the-case-of-hedge-funds.html">Empirical Characteristics of Dynamic Trading Strategies: The Case of Hedge Funds</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../10/06/orange-juice-and-weath.html">Orange Juice and Weather</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../10/04/the-adaptive-markets-hypothesis-market-efficiency-from-an-evolutionary-perspective.html">The Adaptive Markets Hypothesis: Market Efficiency from an Evolutionary Perspective</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../10/02/do-asset-prices-reflect-fundamentals-freshly-squeezed-evidence-from-the-oj-market.html">Do Asset Prices Reflect Fundamentals?  Freshly Squeezed Evidence from the OJ Market</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../09/30/neuroeconomics-how-neuroscience-can-inform-economics.html">Neuroeconomics: How Neuroscience Can Inform Economics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../09/28/drawing-inferences-from-statistics-based-on-multiyear-asset-returns.html">Drawing Inferences from Statistics based on Multiyear Asset Returns</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../09/26/when-are-contrarian-profits-due-to-stock-market-overreaction.html">When are Contrarian Profits Due to Stock Market Overreaction?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../09/24/profitability-of-momentum-strategies-an-evaluation-of-alternative-explanations.html">Profitability of Momentum Strategies: An Evaluation of Alternative Explanations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../09/22/the-restrictions-on-predictability-implied-by-rational-asset-pricing.html">The Restrictions on Predictability Implied by Rational Asset Pricing Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../09/20/the-myth-of-long-horizon-predictability.html">The Myth of Long-Horizon Predictability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../09/18/the-standard-error-of-regressions.html">The Standard Error of Regressions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../09/16/lets-take-the-con-out-of-econometrics.html">Let’s Take the Con Out of Econometrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../09/14/role-of-models-in-statistical-analysis.html">Role of Models in Statistical Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../09/12/the-experimental-generation-of-interpersonal-closeness-a-procedure-and-some-preliminary-findings.html">The Experimental Generation of Interpersonal Closeness: A Procedure and Some Preliminary Findings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../08/02/notes-on-tensorflow.html">Notes on TensorFlow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../08/01/tensorflow-tensorboard-and-docker.html">TensorFlow, TensorBoard, and Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../01/13/review-and-analysis-of-solutions-of-the-three-point-perspective-pose-estimation-problem.html">Review and Analysis of Solutions of the Three Point Perspective Pose Estimation Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../01/12/variational-learning-for-switching-state-space-models.html">Variational Learning for Switching State-Space Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../01/11/bayesian-face-recognition.html">Bayesian Face Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../01/10/robust-generative-subspace-modeling-the-subspace-t-distribution.html">Robust Generative Subspace Modeling: The Subspace <span class="math notranslate nohighlight">\(t\)</span> Distribution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../01/09/robust-subspace-mixture-models-using-t-distributions.html">Robust Subspace Mixture Models using <span class="math notranslate nohighlight">\(t\)</span>-distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../01/08/robust-mixture-modelling-using-the-t-distribution.html">Robust Mixture Modelling using the <span class="math notranslate nohighlight">\(t\)</span>-distribution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../01/07/mixtures-of-probabilistic-principal-component-analyzers.html">Mixtures of Probabilistic Principal Component Analysers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../01/06/the-em-algorithm-for-mixtures-of-factor-analyzers.html">The EM Algorithm for Mixtures of Factor Analyzers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../01/05/3d-live-real-time-captured-content-for-mixed-reality.html">3D Live: Real Time Captured Content for Mixed Reality</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../01/04/high-accuracy-stereo-depth-maps-using-structured-light.html">High-Accuracy Stereo Depth Maps Using Structured Light</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../01/03/simple-accurate-and-robust-projector-camera-calibration.html">Simple, Accurate, and Robust Projector-Camera Calibration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../01/02/multiresolution-gray-scale-and-rotation-invariant-texture-classification-with-local-binary-patterns.html">Multiresolution Gray Scale and Rotation Invariant Texture Classification with Local Binary Patterns</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../01/01/generative-or-discriminative-getting-the-best-of-both-worlds.html">Generative or Discriminative?  Getting the Best of Both Worlds</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/02/01/seda-an-architecture-for-well-conditioned,-scalable-internet-services.html">SEDA: An Architecture for Well-Conditioned, Scalable Internet Services</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/26/reconciling-environment-integration-and-component-independence.html">Reconciling Environment Integration and Component Independence</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/25/design-patterns-abstraction-and-reuse-of-object-oriented-design.html">Design Patterns: Abstraction and Reuse of Object-Oriented Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/24/a-guide-to-metaphorical-design.html">A Guide to Metaphorical Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/23/a-spiral-model-of-software-development-and-enhancement.html">A Spiral Model of Software Development and Enhancement</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/22/sequential-and-concurrent-object-oriented-programming.html">Sequential and Concurrent Object-Oriented Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/21/software-aging.html">Software Aging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/20/applying-design-by-contract.html">Applying “Design by Contract”</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/19/predicate-logic-for-software-engineering.html">Predicate Logic for Software Engineering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/18/active-design-reviews-principles-and-practices.html">Active Design Reviews: Principles and Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/17/a-rational-design-process-how-and-why-to-fake-it.html">A Rational Design Process: How and Why to Fake It</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/16/the-modular-structure-of-complex-systems.html">The Modular Structure of Complex Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/15/abstract-types-defined-as-classes-of-variables.html">Abstract Types Defined as Classes of Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/14/use-of-abstract-interfaces-in-the-development-of-software-for-embedded-computer-systems.html">Use of Abstract Interfaces in the Development of Software for Embedded Computer Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/13/the-influence-of-software-structure-on-reliability.html">The Influence of Software Structure on Reliability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/12/response-to-detected-errors-in-well-structured-programs.html">Response to Detected Errors in Well-Structured Programs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/11/the-use-of-abstract-data-types-to-simplify-program-modifications.html">The Use of Abstract Data Types to Simplify Program Modifications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/10/use-of-the-concept-of-transparency-in-the-design-of-hierarchically-structured-systems.html">Use of the Concept of Transparency in the Design of Hierarchically Structured Systems</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/09/designing-software-for-ease-of-extension-and-contraction.html">Designing Software for Ease of Extension and Contraction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/08/on-the-design-and-development-of-program-families.html">On the Design and Development of Program Families</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/07/on-the-criteria-to-be-used-in-decomposing-systems-into-modules.html">On the Criteria to be Used in Decomposing Systems into Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/06/a-technique-for-software-module-specification-with-examples.html">A Technique for Software Module Specification with Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/05/information-distribution-aspects-of-design-methodology.html">Information Distribution Aspects of Design Methodology</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/04/a-model-of-large-program-development.html">A Model of Large Program Development</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/03/architectural-styles-and-the-design-of-network-based-software-architectures.html">Architectural Styles and the Design of Network-based Software Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/02/design-of-design.html">Design of Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2014/01/01/notes-on-the-synthesis-of-form.html">Notes on the Synthesis of Form</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/26/blogging-with-docker.html">Blogging with Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/25/typical-mercurial-usage.html">Typical Mercurial Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/24/profiling-on-linux.html">Profiling on Linux</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/23/trading-cryptocurrencies.html">Trading Cryptocurrencies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/22/notes-on-software-design.html">Notes on Software Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/21/notes-on-scraping-together-a-heterogeneous-system.html">Notes on Scraping Together a Heterogeneous System</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/20/transfer-media-files-to-mobile-device-via-vlc.html">Transfer Media Files to Mobile Device via VLC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/19/style-lessons-in-clarity-and-grace.html">Style: Lessons in Clarity and Grace</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/18/the-science-of-scientific-writing.html">The Science of Scientific Writing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/17/collection-of-notes-on-research.html">Collection of Notes on Research</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/16/typical-ffmpeg-usage.html">Typical FFmpeg Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/15/generate-svg-graphics.html">Generate SVG Graphics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/14/blogging-with-restructuredtext-a-google-domain-and-sphinx.html">Blogging with RestructuredText, a Google Domain, and Sphinx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/13/set-up-android-development-environment.html">Set Up Android Development Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/12/svegan-lifestyle.html">Svegan Lifestyle</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/11/set-up-system-programming-environment.html">Set Up System Programming Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/10/the-rise-and-fall-of-react-flux-redux-and-cycle.html">The Rise and Fall of React, Flux, Redux, and Cycle</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/09/install-graphics-and-compute-linux-mint.html">Install Graphics and Compute on Linux Mint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/08/set-up-web-development-environment.html">Set Up Web Development Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/07/vfio-tips-and-tricks.html">VFIO Tips and Tricks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/06/options-trading.html">Options Trading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/05/assimp-mesh-loader.html">Assimp Mesh Loader</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/04/set-up-data-analysis-environment.html">Set Up Data Analysis Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/03/install-nvidia-drivers-on-linux-mint.html">Install Nvidia Drivers on Linux Mint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/02/blogging-with-restructuredtext-a-google-domain-and-pelican.html">Blogging with RestructuredText, a Google Domain, and Pelican</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../2013/01/01/linux-mint-installation.html">Linux Mint Installation</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../nb/an-invitation-to-3d-vision-msks/index.html">An Invitation to 3-D Vision - Ma, Soatto, Kosecka, and Sastry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nb/complete-musician-laitz/index.html">The Complete Musician: An Integrated Approach to Tonal Theory, Analysis, and Listening - Laitz</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nb/computer-science-theory-for-the-information-age-hk/index.html">Computer Science Theory for the Information Age - Hopcroft &amp; Kannan</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nb/computer-vision-models-learning-and-inference-prince/index.html">Computer Vision: Models, Learning, and Inference - Prince</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nb/creativity-nlph/index.html">Creativity - NLPH</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nb/differential-geometry-from-a-graphics-perspective-nlph/index.html">Differential Geometry from a Graphics Perspective - NLPH</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nb/fundamentals-of-electric-circuits-as/index.html">Fundamentals of Electric Circuits - Alexander &amp; Sadiku</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nb/linear-programming-vanderbei/index.html">Linear Programming - Vanderbei</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nb/multiple-view-geometry-hz/index.html">Multiple View Geometry in Computer Vision - Hartley &amp; Zisserman</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nb/numerical-methods-for-unconstrained-optimization-and-nonlinear-equations-ds/index.html">Numerical Methods for Unconstrained Optimization and Nonlinear Equations - Dennis &amp; Schnabel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nb/pattern-recognition-and-machine-learning-bishop/index.html">Pattern Recognition and Machine Learning - Bishop</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nb/reinforcement-learning-sb/index.html">Reinforcement Learning: An Introduction - Sutton &amp; Barto</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nb/stat-labs-ns/index.html">Stat Labs - Nolan &amp; Speed</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain</a><ul>
<li><a class="reference internal" href="#motivation-s">Motivation(s)</a></li>
<li><a class="reference internal" href="#proposed-solution-s">Proposed Solution(s)</a></li>
<li><a class="reference internal" href="#evaluation-s">Evaluation(s)</a></li>
<li><a class="reference internal" href="#future-direction-s">Future Direction(s)</a></li>
<li><a class="reference internal" href="#question-s">Question(s)</a></li>
<li><a class="reference internal" href="#analysis">Analysis</a></li>
<li><a class="reference internal" href="#notes">Notes</a><ul>
<li><a class="reference internal" href="#the-hayek-hebb-synaptic-model">The Hayek/Hebb Synaptic Model</a></li>
<li><a class="reference internal" href="#organization-of-a-perceptron">Organization of a Perceptron</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
  <li>
    <a href="../27/geometric-skinning-with-approximate-dual-quaternion-blending.html" title="Previous Chapter: Geometric Skinning with Approximate Dual Quaternion Blending"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; Geometric Ski...</span>
    </a>
  </li>
  <li>
    <a href="../25/the-sharpe-ratio.html" title="Next Chapter: The Sharpe Ratio"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">The Sharpe Ratio &raquo;</span>
    </a>
  </li>
              
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../../../../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <div class="section" id="the-perceptron-a-probabilistic-model-for-information-storage-and-organization-in-the-brain">
<h1>The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain<a class="headerlink" href="#the-perceptron-a-probabilistic-model-for-information-storage-and-organization-in-the-brain" title="Permalink to this headline">¶</a></h1>
<div class="section" id="motivation-s">
<h2>Motivation(s)<a class="headerlink" href="#motivation-s" title="Permalink to this headline">¶</a></h2>
<p>Sensory physiology have achieved appreciable understanding of how information
about the physical world is sensed by the biological system.  The remaining
fundamental questions still shrouding our apprehension of human intelligence are</p>
<ul class="simple">
<li><p>In what form is information stored, or remembered?</p></li>
<li><p>How does information contained in storage, or in memory, influence recognition
and behavior?</p></li>
</ul>
<p>These questions are currently being addressed by two dominant models: symbolic
versus connectionist.</p>
<p>The symbolic model suggests that storage of sensory information is in the form
of coded representations or images, with some sort of one-to-one mapping between
the sensory stimulus and the stored pattern.  The appeal of this hypothesis is
its simplicity and similarities to a computer.  Unfortunately, this method of
information retention requires a systematic comparison of the contents of
storage with incoming sensory patterns in order to determine whether the current
stimulus has been seen before and the appropriate response from the organism.</p>
<p>The connectionist model puts forward that the images of stimuli may never really
be recorded at all, and that the nervous system simply acts as an intricate
switching network where retention takes the form of new connections or
pathways between centers of activity.  Since the stored information takes the
form of new connections, a new stimuli will make use of new pathways
automatically activating the appropriate response.</p>
</div>
<div class="section" id="proposed-solution-s">
<h2>Proposed Solution(s)<a class="headerlink" href="#proposed-solution-s" title="Permalink to this headline">¶</a></h2>
<p>The author proposes a hypothetical nervous system called a perceptron based on
the following physical parameters:</p>
<dl class="simple">
<dt>x</dt><dd><p>The number of excitatory connections per A-unit.</p>
</dd>
<dt>y</dt><dd><p>The number of inhibitory connections per A-unit.</p>
</dd>
<dt><span class="math notranslate nohighlight">\(\theta\)</span></dt><dd><p>The expected threshold of an A-unit.</p>
</dd>
<dt><span class="math notranslate nohighlight">\(\omega\)</span></dt><dd><p>The proportion of R-units to which an A-unit is connected.</p>
</dd>
<dt><span class="math notranslate nohighlight">\(N_A\)</span></dt><dd><p>The number of A-units in the system.</p>
</dd>
<dt><span class="math notranslate nohighlight">\(N_R\)</span></dt><dd><p>The number of R-units in the system.</p>
</dd>
<dt><span class="math notranslate nohighlight">\(N_S\)</span></dt><dd><p>The number of S-units in the system.</p>
</dd>
</dl>
<p>The current perceptron does not handle temporal stimulus.  Since the precise
structure of a biological system is unknown, the accompanying analysis makes
use of probability theory.  This proposed theory of statistical separability is
based on the Hayek/Hebb Synaptic Model.  The alternative symbolic logic brain
models fail to capture equipotentiality and lack neurological correlates.  The
author asserts that refining these models can never account for biological
intelligence because of a difference in principle.</p>
</div>
<div class="section" id="evaluation-s">
<h2>Evaluation(s)<a class="headerlink" href="#evaluation-s" title="Permalink to this headline">¶</a></h2>
<p>The different modes of organization of a perceptron can be decomposed into</p>
<ul class="simple">
<li><p>logical characteristics (<span class="math notranslate nohighlight">\(\alpha, \beta, \gamma\)</span>),</p></li>
<li><p>discriminanting response systems (mean <span class="math notranslate nohighlight">\(\mu\)</span> versus sum <span class="math notranslate nohighlight">\(\sum\)</span>),
and</p></li>
<li><p>reinforcement systems (monovalent versus bivalent).</p></li>
</ul>
<p>In the uncompensated gain <span class="math notranslate nohighlight">\(\alpha\)</span>-system, an A-unit gains an increment of
value for every impulse and holds this gain indefinitely.  In the constant feed
<span class="math notranslate nohighlight">\(\beta\)</span>-system, each source-set is allowed a constant rate of gain; the
increment is apportioned among the cells of the source-set in proportion to
their activity.  In the parasitic gain <span class="math notranslate nohighlight">\(\gamma\)</span>-system, A-units gain in
value at the expense of the inactive units of their source-set so that the total
value of the source-set is always constant.  The responses of these systems to a
stimulus are studied in the context of inactive R-units (predominant phase).
The overall performance trend is <span class="math notranslate nohighlight">\(\gamma &gt; \alpha &gt; \beta\)</span>.</p>
<p>When the R-units are active (postdominant phase), activity is limited to a
single source-set as the other sets are suppressed.  To understand how the
dominant response affects performance, the author restricts the system to
mean-discriminanting versus sum-discriminanting.  In the former, the R-units
whose inputs have the greatest mean value responds first.  The latter gives the
advantage to the response whose inputs have the greatest net value.  The
experiments indicate that <span class="math notranslate nohighlight">\(\alpha\)</span> and <span class="math notranslate nohighlight">\(\beta\)</span> system performance
are poorer for the <span class="math notranslate nohighlight">\(\sum\)</span> model than the <span class="math notranslate nohighlight">\(\mu\)</span> case.  However, it
makes no difference in performance which model is used for the
<span class="math notranslate nohighlight">\(\gamma\)</span>-system.</p>
<p>The foregoing analysis uses only positive reinforcement (i.e. monovalent).  In
a bivalent system, one can give positive and negative feedback, and an A-unit
may either gain or lose in value depending on the state of the system.  The
author mentioned that both paradigms perform similarly, but monovalent systems
are more efficient.</p>
<p>These results demonstrate that the perceptron surpass existing learning and
behavior theories in terms of parsimony, verifiability, and explanatory power
and generality.  The perceptron only requires each A-unit to carry a
hypothetical variable <span class="math notranslate nohighlight">\(V\)</span> that adheres to certain functional
characteristics.  When the perceptron fails to adapt in a new situation, one can
be confident that either the architecture or the empirical measurements are
wrong.  The overall theory enables one to reduce complicated tasks to a
supervised learning problem and analyze the relationship between neurological
variables and learning curves.</p>
<p>The limits of a perceptron lie in the area of relative judgement and the
abstraction of relationships.  What is learnable are tasks like naming the color
if the stimulus is on the left and the shape if it is on the right.  Statistical
separability alone does not provide a sufficient basis for higher order
abstractions such as name the object left of the square and indicate the pattern
that appeared before the circle.</p>
</div>
<div class="section" id="future-direction-s">
<h2>Future Direction(s)<a class="headerlink" href="#future-direction-s" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>How to utilize the activation pathways of a neural network to predict the
overall accuracy of the system?</p></li>
<li><p>How to quantify the capacity of a system given that one can quantify how much
the new associations degrade the old associations?</p></li>
</ul>
</div>
<div class="section" id="question-s">
<h2>Question(s)<a class="headerlink" href="#question-s" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Did the author mean that monovalent systems are more efficient to train?</p></li>
<li><p>Are the A-units in the projection area simply routing the input signals?</p></li>
<li><p>The author quantifies the capacity of a system as the probability that a
stimulus which has been associated to one of two responses will retain its
proper preference after the system has saturated to a given level.  Isn’t this
just the confusion matrix?  Wouldn’t this make more sense as an accuracy
measure?</p></li>
<li><p>Could the inhibitory connections be interpreted as
<a class="reference internal" href="../14/dropout-a-simple-way-to-prevent-neural-networks-from-overfitting.html"><span class="doc">preventing co-adaptation of feature detectors</span></a>?</p></li>
</ul>
</div>
<div class="section" id="analysis">
<h2>Analysis<a class="headerlink" href="#analysis" title="Permalink to this headline">¶</a></h2>
<p>In hindsight, this paper illustrates that it is possible to implement a linear
classifier when a linearly separable set of binary characteristics (i.e.
features) is known.  Note that the perceptron as presented here does not include
any <a class="reference internal" href="../05/multilayer-feedforward-networks-are-universal-approximators.html"><span class="doc">hidden layers</span></a>.</p>
<p>The most significant flaw is that the schematic diagrams of a perceptron are too
convoluted compared to the ones in <a class="bibtex reference internal" href="#rosenblatt1957perceptron" id="id1">[Ros57]</a>.  It tries
to illustrate a perceptron operates with random connections and can be daisy
chained at the expense of decreased clarity.  It is difficult to glean from the
latest illustration that a response set consists of mutually exclusive R-units.</p>
<p>The author’s specification of communality goes against the current trend of
learning the right features.  Although the system analysis is interesting, it is
not obvious how it will extend to multilayer perceptrons.</p>
<p>The most interesting and valuable idea (but not covered in these papers) is the
perceptron convergence theorem <a class="bibtex reference internal" href="#mohri2013perceptron" id="id2">[MR13]</a>.  Note that the
perceptron algorithm is described vaguely by <a class="bibtex reference internal" href="#rosenblatt1958perceptron" id="id3">[Ros58]</a> as</p>
<div class="math notranslate nohighlight">
\[\min \frac{1}{N} \sum_i \max\left\{
  0, -y_i \mathbf{w} \cdot \mathbf{x}_i
\right\}\]</div>
<p>where <span class="math notranslate nohighlight">\(\left\{ \mathbf{x}_i \in \mathbb{R}^n,
y_i \in \{-1, 1\}) \right\}_{i = 1}^N\)</span> are the desired pairs of input and
output, and <span class="math notranslate nohighlight">\(\mathbf{w} \in \mathbb{R}^n\)</span> denotes a separating hyperplane.
Notice that the gradient of this hinge loss corresponds to the proposed
perceptron learning rule</p>
<div class="math notranslate nohighlight">
\[\mathbf{w}_{t + 1} = \mathbf{w}_t - \nabla_{\mathbf{w}}.\]</div>
</div>
<div class="section" id="notes">
<h2>Notes<a class="headerlink" href="#notes" title="Permalink to this headline">¶</a></h2>
<div class="section" id="the-hayek-hebb-synaptic-model">
<h3>The Hayek/Hebb Synaptic Model<a class="headerlink" href="#the-hayek-hebb-synaptic-model" title="Permalink to this headline">¶</a></h3>
<ol class="arabic simple">
<li><p>The physical connections of the nervous system which are involved in learning
and recognition are not identical from one organism to another.  At birth,
the construction of the most important networks is largely random, subject to
a minimum number of genetic constraints.</p></li>
<li><p>The original system of connected cells is capable of a certain amount of
plasticity; after a period of neural activity, the probability that a
stimulus applied to one set of cells will cause a response in some other set
is likely to change, due to some relatively long-lasting changes in the
neurons themselves.</p></li>
<li><p>Through exposure to a large sample of stimuli, those which are most similar
will tend to form pathways to the same sets of responding cells.  Those which
are markedly dissimilar will tend to develop connections to different sets of
responding cells.</p></li>
<li><p>The application of positive and/or negative reinforcement may facilitate or
hinder whatever formation of connections is currently in progress.</p></li>
<li><p>Similarity is represented at some level of the nervous system by a tendency
of similar stimuli to activate the same sets of cells.  It depends on the
physical organization of the perceiving system.  The structure of the
constantly evolving system will determine the classes of things into which
the perceptual world is divided.</p></li>
</ol>
</div>
<div class="section" id="organization-of-a-perceptron">
<h3>Organization of a Perceptron<a class="headerlink" href="#organization-of-a-perceptron" title="Permalink to this headline">¶</a></h3>
<dl class="simple">
<dt>Sensory Units (S-points)</dt><dd><p>Respond to stimuli on an all-or-nothing basis, or with a pulse
amplitude/frequency proportional to the stimulus intensity.  Impulses are
transmitted to a set of A-units.  Any particular S-A connection may be either
positive (excitatory) or negative (inhibitory).</p>
</dd>
<dt>Association Units (A-units)</dt><dd><p>Outputs a value to one or more R-units based on its history and logical
characteristics.  The set of S-points transmitting impulses to a particular
A-unit will be called the origin points of that A-unit.</p>
</dd>
<dt>Response Units (R-units)</dt><dd><p>Fires according to the McCulloch-Pitts linear threshold unit whose activation
function is either mean-discriminanting or sum-discriminanting.  Each R-unit
feeds back impulses which inhibit the activity of all mutually exclusive
R-units and the A-units that might activate them.</p>
</dd>
</dl>
<p>In contrast to the illustration of the perceptron in
<a class="bibtex reference internal" href="#rosenblatt1957perceptron" id="id4">[Ros57]</a>, <a class="bibtex reference internal" href="#rosenblatt1958perceptron" id="id5">[Ros58]</a> introduces
additional A-units in the form of a projection area.  It is important to realize
that the A-units in the projection area are not hidden units; they merely
implement the switching functions between source and sink.</p>
<p>Notice that the inhibitory connections from the S-points are necessary because
a large, complex pattern would always activate any of the A-units which
might be activated by its component sub-patterns.  Including S-point inhibitory
guarantees that the set of A-units responding to a part will generally contain
some members which will be inhibited when the whole is presented.</p>
<p>The communality (overlap) between different sets of A-units leads to a
statistical interaction between the associations formed.  Although this may
result in interference between associations, the system gains the ability of
combinatorial representations.</p>
<p class="rubric">References</p>
<p id="bibtex-bibliography-blog/2016/11/26/the-perceptron-a-probabilistic-model-for-information-storage-and-organization-in-the-brain-0"><dl class="citation">
<dt class="bibtex label" id="mohri2013perceptron"><span class="brackets"><a class="fn-backref" href="#id2">MR13</a></span></dt>
<dd><p>Mehryar Mohri and Afshin Rostamizadeh. Perceptron mistake bounds. <em>arXiv preprint arXiv:1305.0208</em>, 2013.</p>
</dd>
<dt class="bibtex label" id="rosenblatt1957perceptron"><span class="brackets">Ros57</span><span class="fn-backref">(<a href="#id1">1</a>,<a href="#id4">2</a>)</span></dt>
<dd><p>Frank Rosenblatt. The perceptron: a perceiving and recognizing automaton. Technical Report, Cornell Aeronautical Laboratory, 1957.</p>
</dd>
<dt class="bibtex label" id="rosenblatt1958perceptron"><span class="brackets">Ros58</span><span class="fn-backref">(<a href="#id3">1</a>,<a href="#id5">2</a>)</span></dt>
<dd><p>Frank Rosenblatt. The perceptron: a probabilistic model for information storage and organization in the brain. <em>Psychological review</em>, 65(6):386, 1958.</p>
</dd>
</dl>
</p>
</div>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
        <br/>
        
<div id="sourcelink">
  <a href="../../../../_sources/blog/2016/11/26/the-perceptron-a-probabilistic-model-for-information-storage-and-organization-in-the-brain.rst.txt"
     rel="nofollow">Source</a>
</div>
      
    </p>
    <p>
        &copy; Copyright 2013-2020, alphaXomega.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.1.2.<br/>
    </p>
  </div>
</footer>
  </body>
</html>